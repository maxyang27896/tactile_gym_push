{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import gym\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, shutil\n",
    "import torch\n",
    "import omegaconf\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import mbrl.env.cartpole_continuous as cartpole_env\n",
    "import mbrl.env.reward_fns as reward_fns\n",
    "import mbrl.env.termination_fns as termination_fns\n",
    "import mbrl.models as models\n",
    "import mbrl.planning as planning\n",
    "import mbrl.util.common as common_util\n",
    "import mbrl.util as util\n",
    "from mbrl.util.math import euler_to_quaternion, quaternion_rotation_matrix\n",
    "\n",
    "import tactile_gym.rl_envs\n",
    "from tactile_gym.sb3_helpers.params import import_parameters\n",
    "from tactile_gym.utils.general_utils import get_orn_diff\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "mpl.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce a display to render image\n",
    "from pyvirtualdisplay import Display\n",
    "_display = Display(visible=False, size=(1400, 900))\n",
    "_ = _display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Training Environment and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo_name': 'ppo', 'env_name': 'object_push-v0', 'max_ep_len': 2000, 'image_size': [128, 128], 'env_modes': {'movement_mode': 'TyRz', 'control_mode': 'TCP_position_control', 'rand_init_orn': False, 'rand_init_pos_y': False, 'rand_obj_mass': False, 'traj_type': 'point', 'observation_mode': 'tactile_pose_relative_data', 'reward_mode': 'dense', 'terminate_early': True, 'terminate_terminate_early': True, 'use_contact': True, 'task': 'goal_pos', 'planar_states': True, 'additional_reward_settings': 'john_guide_off', 'importance_obj_goal_pos': 1.0, 'importance_obj_goal_orn': 1.0, 'importance_tip_obj_orn': 1.0, 'terminated_early_penalty': -100, 'reached_goal_reward': 100, 'tcp_lims': [[-0.1, 0.3], [-0.3, 0.3], [-0.0, 0.0], [-0.0, 0.0], [-0.0, 0.0], [-3.141592653589793, 3.141592653589793]], 'goal_edges': [(1, 0)], 'goal_ranges': [0.0, 0.27, -0.18, 0.18]}, 'policy': 'MultiInputPolicy', 'seed': 1, 'n_stack': 1, 'total_timesteps': 1000000, 'n_eval_episodes': 10, 'n_envs': 10, 'eval_freq': 2000.0}\n",
      "{'policy_kwargs': {'features_extractor_class': <class 'tactile_gym.sb3_helpers.custom.custom_torch_layers.CustomCombinedExtractor'>, 'features_extractor_kwargs': {'cnn_base': <class 'stable_baselines3.common.torch_layers.NatureCNN'>, 'cnn_output_dim': 256, 'mlp_extractor_net_arch': [64, 64]}, 'net_arch': [{'pi': [256, 256], 'vf': [256, 256]}], 'activation_fn': <class 'torch.nn.modules.activation.Tanh'>}, 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.95, 'gae_lambda': 0.9, 'clip_range': 0.2, 'clip_range_vf': None, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'use_sde': False, 'sde_sample_freq': -1, 'target_kl': 0.1}\n",
      "argv[0]=\n",
      "Loaded EGL 1.5 after reload.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Mar  8 2021 17:26:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GL_VENDOR=NVIDIA Corporation\n",
      "GL_RENDERER=NVIDIA GeForce RTX 3090/PCIe/SSE2\n",
      "GL_VERSION=4.6.0 NVIDIA 495.29.05\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60 NVIDIA\n",
      "Version = 4.6.0 NVIDIA 495.29.05\n",
      "Vendor = NVIDIA Corporation\n",
      "Renderer = NVIDIA GeForce RTX 3090/PCIe/SSE2\n",
      "ven = NVIDIA Corporation\n",
      "ven = NVIDIA Corporation\n"
     ]
    }
   ],
   "source": [
    "# Make the pushing environment\n",
    "algo_name = 'ppo'\n",
    "env_name = 'object_push-v0'\n",
    "rl_params, algo_params, augmentations = import_parameters(env_name, algo_name)\n",
    "rl_params[\"env_modes\"][ 'observation_mode'] = 'tactile_pose_relative_data'\n",
    "rl_params[\"env_modes\"][ 'control_mode'] = 'TCP_position_control'\n",
    "# rl_params[\"env_modes\"]['movement_mode'] = 'TxTyRz'\n",
    "rl_params[\"max_ep_len\"] = 2000\n",
    "\n",
    "rl_params[\"env_modes\"][ 'terminate_early']  = True\n",
    "rl_params[\"env_modes\"]['terminate_terminate_early'] = True\n",
    "rl_params[\"env_modes\"][ 'use_contact'] = True\n",
    "rl_params[\"env_modes\"][ 'traj_type'] = 'point'\n",
    "rl_params[\"env_modes\"][ 'task'] = \"goal_pos\"\n",
    "rl_params[\"env_modes\"]['planar_states'] = True\n",
    "\n",
    "rl_params[\"env_modes\"][ 'reward_mode'] = \"dense\"\n",
    "rl_params[\"env_modes\"]['additional_reward_settings'] = 'john_guide_off'\n",
    "rl_params[\"env_modes\"]['importance_obj_goal_pos'] = 1.0\n",
    "rl_params[\"env_modes\"]['importance_obj_goal_orn'] = 1.0\n",
    "rl_params[\"env_modes\"]['importance_tip_obj_orn'] = 1.0\n",
    "rl_params[\"env_modes\"]['terminated_early_penalty'] = -100\n",
    "rl_params[\"env_modes\"]['reached_goal_reward'] = 100\n",
    "\n",
    "# set limits and goals\n",
    "TCP_lims = np.zeros(shape=(6, 2))\n",
    "TCP_lims[0, 0], TCP_lims[0, 1] = -0.1, 0.3  # x lims\n",
    "TCP_lims[1, 0], TCP_lims[1, 1] = -0.3, 0.3  # y lims\n",
    "TCP_lims[2, 0], TCP_lims[2, 1] = -0.0, 0.0  # z lims\n",
    "TCP_lims[3, 0], TCP_lims[3, 1] = -0.0, 0.0  # roll lims\n",
    "TCP_lims[4, 0], TCP_lims[4, 1] = -0.0, 0.0  # pitch lims\n",
    "TCP_lims[5, 0], TCP_lims[5, 1] = -180 * np.pi / 180, 180 * np.pi / 180  # yaw lims\n",
    "\n",
    "# goal parameter\n",
    "# goal_edges = [(0, -1), (0, 1), (1, 0)] # Top bottom and stright\n",
    "goal_edges = [(1, 0)]\n",
    "goal_x_max = np.float64(TCP_lims[0, 1] * 0.9).item()\n",
    "goal_x_min = 0.0 # np.float64(TCP_lims[0, 0] * 0.6).item()\n",
    "goal_y_max = np.float64(TCP_lims[1, 1] * 0.6).item()\n",
    "goal_y_min = np.float64(TCP_lims[1, 0] * 0.6).item()\n",
    "goal_ranges = [goal_x_min, goal_x_max, goal_y_min, goal_y_max]\n",
    "\n",
    "rl_params[\"env_modes\"]['tcp_lims'] = TCP_lims.tolist()\n",
    "rl_params[\"env_modes\"]['goal_edges'] = goal_edges\n",
    "rl_params[\"env_modes\"]['goal_ranges'] = goal_ranges\n",
    "\n",
    "print(rl_params)\n",
    "print(algo_params)\n",
    "\n",
    "env_kwargs={\n",
    "    'show_gui':False,\n",
    "    'show_tactile':False,\n",
    "    'max_steps':rl_params[\"max_ep_len\"],\n",
    "    'image_size':rl_params[\"image_size\"],\n",
    "    'env_modes':rl_params[\"env_modes\"],\n",
    "}\n",
    "env = gym.make(env_name, **env_kwargs)\n",
    "\n",
    "seed = 0\n",
    "env.seed(seed)\n",
    "rng = np.random.default_rng(seed=0)\n",
    "generator = torch.Generator(device=device)\n",
    "generator.manual_seed(seed)\n",
    "obs_shape = env.observation_space.shape\n",
    "act_shape = env.action_space.shape\n",
    "\n",
    "# This functions allows the model to evaluate the true rewards given an observation \n",
    "reward_fn = reward_fns.cartpole\n",
    "# This function allows the model to know if an observation should make the episode end\n",
    "term_fn = termination_fns.cartpole\n",
    "\n",
    "# Define model working directorys\n",
    "# work_dir = os.path.join(os.getcwd(), 'saved_model')\n",
    "work_dir = os.path.join(os.getcwd(), 'training_cfg')\n",
    "if not os.path.exists(work_dir):\n",
    "    os.mkdir(work_dir)\n",
    "else:\n",
    "    for filename in os.listdir(work_dir):\n",
    "        file_path = os.path.join(work_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000869 0.000002 0.000003 1.000000 0.000000 0.000000 0.000000 1.000000]\n",
      "[0.000869 0.000002 0.000003 1.000000 0.000000 0.000000 0.000000 1.000000]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(env.reset())\n",
    "print(env.get_observation())\n",
    "print(type(env.get_observation()))\n",
    "# print(env.get_tactile_pose_obs_goal_exluded())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(8,)\n",
      "Box(2,)\n",
      "(8,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(obs_shape)\n",
    "print(act_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_length = env._max_steps\n",
    "num_trials = 1\n",
    "ensemble_size = 5\n",
    "initial_buffer_size = 2000\n",
    "buffer_size = num_trials * trial_length\n",
    "target_normalised = True\n",
    "\n",
    "# Everything with \"???\" indicates an option with a missing value.\n",
    "# Our utility functions will fill in these details using the \n",
    "# environment information\n",
    "cfg_dict = {\n",
    "    # dynamics model configuration\n",
    "    \"dynamics_model\": {\n",
    "        \"_target_\": \"mbrl.models.GaussianMLP\",\n",
    "        \"device\": device,\n",
    "        \"num_layers\": 3,\n",
    "        \"ensemble_size\": ensemble_size,\n",
    "        \"hid_size\": 200,\n",
    "        \"in_size\": \"???\",\n",
    "        \"out_size\": \"???\",\n",
    "        \"deterministic\": False,\n",
    "        \"propagation_method\": \"fixed_model\",\n",
    "        # can also configure activation function for GaussianMLP\n",
    "        \"activation_fn_cfg\": {\n",
    "            \"_target_\": \"torch.nn.LeakyReLU\",\n",
    "            \"negative_slope\": 0.01\n",
    "        }\n",
    "    },\n",
    "    # options for training the dynamics model\n",
    "    \"algorithm\": {\n",
    "        \"learned_rewards\": False,\n",
    "        \"target_is_delta\": True,\n",
    "        \"normalize\": True,\n",
    "        \"target_normalize\": target_normalised,\n",
    "        \"dataset_size\": buffer_size\n",
    "    },\n",
    "    # these are experiment specific options\n",
    "    \"overrides\": {\n",
    "        \"trial_length\": trial_length,\n",
    "        \"num_steps\": num_trials * trial_length,\n",
    "        \"model_batch_size\": 32,\n",
    "        \"validation_ratio\": 0.05\n",
    "    }\n",
    "}\n",
    "cfg = omegaconf.OmegaConf.create(cfg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qt21590/anaconda3/envs/tactile_gym_mbrl/lib/python3.9/site-packages/hydra/utils.py:32: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if OmegaConf.is_none(config):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneDTransitionRewardModel(\n",
      "  (model): GaussianMLP(\n",
      "    (hidden_layers): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): EnsembleLinearLayer(num_members=5, in_size=10, out_size=200, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): EnsembleLinearLayer(num_members=5, in_size=200, out_size=200, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): EnsembleLinearLayer(num_members=5, in_size=200, out_size=200, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "    (mean_and_logvar): EnsembleLinearLayer(num_members=5, in_size=200, out_size=16, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "\n",
    "# Create a gym-like environment to encapsulate the model\n",
    "model_env = models.ModelEnvPushing(env, dynamics_model, termination_fn=None, reward_fn=None, generator=generator)\n",
    "\n",
    "print(dynamics_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_type = \"cem\"\n",
    "\n",
    "if optimizer_type == \"cem\":\n",
    "    optimizer_cfg = {\n",
    "            \"_target_\": \"mbrl.planning.CEMOptimizer\",\n",
    "            \"num_iterations\": 5,\n",
    "            \"elite_ratio\": 0.1,\n",
    "            \"population_size\": 500,\n",
    "            \"alpha\": 0.1,\n",
    "            \"device\": device,\n",
    "            \"lower_bound\": \"???\",\n",
    "            \"upper_bound\": \"???\",\n",
    "            \"return_mean_elites\": True,\n",
    "            \"clipped_normal\": False\n",
    "        }\n",
    "elif optimizer_type == \"mppi\":\n",
    "    optimizer_cfg = {\n",
    "            \"_target_\": \"mbrl.planning.MPPIOptimizer\",\n",
    "            \"num_iterations\": 5,\n",
    "            \"gamma\": 1.0,\n",
    "            \"population_size\": 500,\n",
    "            \"sigma\": 0.95,\n",
    "            \"beta\": 0.7,\n",
    "            \"lower_bound\": \"???\",\n",
    "            \"upper_bound\": \"???\",\n",
    "            \"device\": device,\n",
    "        }\n",
    "\n",
    "elif optimizer_type == \"icem\":\n",
    "    optimizer_cfg = {\n",
    "            \"_target_\": \"mbrl.planning.ICEMOptimizer\",\n",
    "            \"num_iterations\": 5,\n",
    "            \"elite_ratio\": 0.1,\n",
    "            \"population_size\": 500,\n",
    "            \"population_decay_factor\": 1.25,\n",
    "            \"colored_noise_exponent\": 2.0,\n",
    "            \"keep_elite_frac\": 0.1,\n",
    "            \"alpha\": 0.1,\n",
    "            \"lower_bound\": \"???\",\n",
    "            \"upper_bound\": \"???\",\n",
    "            \"device\": device,\n",
    "        }\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "\n",
    "agent_cfg = omegaconf.OmegaConf.create({\n",
    "    # this class evaluates many trajectories and picks the best one\n",
    "    \"_target_\": \"mbrl.planning.TrajectoryOptimizerAgent\",\n",
    "    \"planning_horizon\": 40,\n",
    "    \"replan_freq\": 1,\n",
    "    \"verbose\": False,\n",
    "    \"action_lb\": \"???\",\n",
    "    \"action_ub\": \"???\",\n",
    "    # this is the optimizer to generate and choose a trajectory\n",
    "    \"optimizer_cfg\": optimizer_cfg\n",
    "})\n",
    "\n",
    "agent = planning.create_trajectory_optim_agent_for_model(\n",
    "    model_env,\n",
    "    agent_cfg,\n",
    "    num_particles=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving config files\n",
    "config_filename = 'cfg_dict'\n",
    "config_dir = os.path.join(work_dir, config_filename)\n",
    "omegaconf.OmegaConf.save(config=cfg, f=config_dir) \n",
    "loaded = omegaconf.OmegaConf.load(config_dir)\n",
    "assert cfg == loaded\n",
    "\n",
    "agent_config_filename = 'agent_cfg'\n",
    "agent_config_dir = os.path.join(work_dir, agent_config_filename)\n",
    "omegaconf.OmegaConf.save(config=agent_cfg, f=agent_config_dir) \n",
    "loaded = omegaconf.OmegaConf.load(agent_config_dir)\n",
    "assert agent_cfg == loaded\n",
    "\n",
    "env_kwargs_filename = 'env_kwargs'\n",
    "env_kwargs_dir = os.path.join(work_dir, env_kwargs_filename)\n",
    "omegaconf.OmegaConf.save(config=env_kwargs, f=env_kwargs_dir) \n",
    "loaded = omegaconf.OmegaConf.load(env_kwargs_dir)\n",
    "assert env_kwargs == loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current goal index 0\n",
      "Position goal trajectory [[0.270000 0.167541 0.000000]]\n",
      "0\n",
      "[[ True  True  True]]\n",
      "[0.270000 0.167541 0.000000]\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(\"Current goal index\", env.targ_traj_list_id)\n",
    "print(\"Position goal trajectory\", env.traj_pos_workframe)\n",
    "# print(\"Orientation goal trajectory\", env.traj_rpy_workframe)\n",
    "# print(\"Orientation goal trajectory\", env.traj_orn_workframe)\n",
    "\n",
    "# All of this can be accessed through model_env.env\n",
    "print(model_env.env.targ_traj_list_id)\n",
    "print(model_env.env.traj_pos_workframe == env.traj_pos_workframe)\n",
    "print(model_env.env.goal_pos_workframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True],\n",
      "        [False],\n",
      "        [False]], device='cuda:0')\n",
      "tensor([[ True],\n",
      "        [False],\n",
      "        [False]], device='cuda:0')\n",
      "tensor([[-100.],\n",
      "        [   0.],\n",
      "        [   0.]], device='cuda:0')\n",
      "tensor([[-100.],\n",
      "        [   0.],\n",
      "        [   0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Test termination function in model env -------------------------\n",
    "early_termination = env.terminate_early\n",
    "def termination(act: torch.Tensor, next_obs: torch.Tensor, rewards:  torch.Tensor) -> torch.Tensor:\n",
    "    '''\n",
    "    Criteria for terminating an episode. Should return a vector of dones of size \n",
    "    population_size x batch_size\n",
    "    '''\n",
    "\n",
    "    if 'reduced' in env.observation_mode: \n",
    "        tcp_pos_to_goal_workframe = next_obs[:, 0:3]\n",
    "        # tcp_orn_to_goal_workframe = next_obs[:, 3:7]\n",
    "        # tcp_lin_vel_workframe = next_obs[:, 7:10]\n",
    "        # tcp_ang_vel_workframe = next_obs[:, 10:13]\n",
    "        cur_obj_pos_to_goal_workframe = next_obs[:, 13:16]\n",
    "        # cur_obj_orn_to_goal_workframe = next_obs[:, 16:20]\n",
    "        # cur_obj_lin_vel_workframe = next_obs[:, 20:23]\n",
    "        # cur_obj_ang_vel_workframe = next_obs[:, 23:26]\n",
    "\n",
    "        tcp_pos_workframe = tcp_pos_to_goal_workframe + goal_pos_workframe_batch\n",
    "        cur_obj_pos_workframe = cur_obj_pos_to_goal_workframe + goal_pos_workframe_batch\n",
    "\n",
    "        # Calculate distance between goal and current positon\n",
    "        obj_goal_pos_dist = torch.linalg.norm(cur_obj_pos_to_goal_workframe, axis=1)\n",
    "    \n",
    "    elif env.observation_mode == 'goal_aware_tactile_pose_data': \n",
    "\n",
    "        if env.planar_states == True: \n",
    "            # tcp_pos_to_goal_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            tcp_orn_to_goal_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "            cur_obj_pos_to_goal_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            cur_obj_orn_to_goal_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "\n",
    "            # tcp_pos_to_goal_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_orn_to_goal_workframe[:, 2:4] = next_obs[:, 0:2]\n",
    "            cur_obj_pos_to_goal_workframe[:, 0:2]= next_obs[:, 2:4]\n",
    "            cur_obj_orn_to_goal_workframe[:, 2:4] = next_obs[:, 4:6]\n",
    "        else:\n",
    "            # tcp_pos_to_goal_workframe = next_obs[:, 0:3]\n",
    "            tcp_orn_to_goal_workframe = next_obs[:, 0:4]\n",
    "            cur_obj_pos_to_goal_workframe = next_obs[:, 4:7]\n",
    "            cur_obj_orn_to_goal_workframe = next_obs[:, 7:11]\n",
    "\n",
    "        # Only take in the x and y coordinates\n",
    "        # tcp_pos_workframe = tcp_pos_to_goal_workframe[:, 0:2] + goal_pos_workframe_batch[:, 0:2]\n",
    "        cur_obj_pos_workframe = cur_obj_pos_to_goal_workframe[:, 0:2] + goal_pos_workframe_batch[:, 0:2]\n",
    "\n",
    "        # Calculate distance between goal and current positon\n",
    "        obj_goal_pos_dist = torch.linalg.norm(cur_obj_pos_to_goal_workframe, axis=1)\n",
    "            \n",
    "    elif env.observation_mode == 'tactile_pose_data': \n",
    "\n",
    "        if env.planar_states == True:\n",
    "            tcp_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float64).to(device)\n",
    "            tcp_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float64).to(device)\n",
    "            cur_obj_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float64).to(device)\n",
    "            cur_obj_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float64).to(device)\n",
    "\n",
    "            tcp_pos_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_orn_workframe[:, 2:4] = next_obs[:, 2:4]\n",
    "            cur_obj_pos_workframe[:, 0:2]= next_obs[:, 4:6]\n",
    "            cur_obj_orn_workframe[:, 2:4] = next_obs[:, 6:8]\n",
    "        else:   \n",
    "\n",
    "            tcp_pos_workframe = next_obs[:, 0:3]\n",
    "            tcp_orn_workframe = next_obs[:, 3:7]\n",
    "            cur_obj_pos_workframe = next_obs[:, 7:10]\n",
    "            cur_obj_orn_workframe = next_obs[:, 10:14]\n",
    "\n",
    "        # Calculate distance between goal and current positon\n",
    "        obj_goal_pos_dist = torch.linalg.norm(cur_obj_pos_workframe - goal_pos_workframe_batch, axis=1)\n",
    "\n",
    "        # calculate tcp to object orn\n",
    "        tcp_to_obj_orn = model_env.get_orn_dist(cur_obj_orn_workframe, tcp_orn_workframe)\n",
    "\n",
    "        tip_to_obj_pos = torch.linalg.norm(tcp_pos_workframe - cur_obj_pos_workframe, axis=1)\n",
    "\n",
    "\n",
    "    elif env.observation_mode == 'tactile_pose_relative_data':\n",
    "\n",
    "        if env.planar_states == True:\n",
    "            tcp_obj_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            tcp_obj_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "            cur_obj_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            cur_obj_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "\n",
    "            tcp_obj_pos_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_obj_orn_workframe[:, 2:4] = next_obs[:, 2:4]\n",
    "            cur_obj_pos_workframe[:, 0:2] = next_obs[:, 4:6]\n",
    "            cur_obj_orn_workframe[:, 2:4] = next_obs[:, 6:8]\n",
    "        else:   \n",
    "            NotImplemented\n",
    "\n",
    "        # Calculate distance between goal and current positon\n",
    "        obj_goal_pos_dist = torch.linalg.norm(cur_obj_pos_workframe[:, 0:2] - goal_pos_workframe_batch[:, 0:2], axis=1)\n",
    "\n",
    "        # calculate tcp to object orn\n",
    "        tcp_to_obj_orn = model_env.get_orn_norm(tcp_obj_orn_workframe)\n",
    "\n",
    "        # Check get orn dist function\n",
    "        # print(tcp_to_obj_orn)   \n",
    "        # print(model_env.get_orn_dist(next_obs[:, 2:4], torch.tensor([0, 1]).to(device)))\n",
    "        # print(model_env.get_orn_norm(tcp_obj_orn_workframe))\n",
    "\n",
    "        # Calculate tip to obj distance \n",
    "        tip_to_obj_pos = torch.linalg.norm(tcp_obj_pos_workframe[:, 0:2], axis=1)\n",
    "\n",
    "    else:\n",
    "        tcp_pos_workframe = next_obs[:, 0:3]\n",
    "        # tcp_rpy_workframe = next_obs[:, 3:6]\n",
    "        # tcp_lin_vel_workframe = next_obs[:, 6:9]\n",
    "        # tcp_ang_vel_workframe = next_obs[:, 9:12]\n",
    "        cur_obj_pos_workframe = next_obs[:, 12:15]\n",
    "        # cur_obj_rpy_workframe = next_obs[:, 15:18]\n",
    "        # cur_obj_lin_vel_workframe = next_obs[:, 18:21]\n",
    "        # cur_obj_ang_vel_workframe = next_obs[:, 21:24]\n",
    "        # pred_goal_pos_workframe = next_obs[:, 24:27]\n",
    "        # pred_goal_rpy_workframe = next_obs[:, 27:30]\n",
    "\n",
    "        # Calculate distance between goal and current positon\n",
    "        obj_goal_pos_dist = torch.linalg.norm(cur_obj_pos_workframe - goal_pos_workframe_batch, axis=1)\n",
    "    \n",
    "    # print('Object position, ', cur_obj_pos_workframe)\n",
    "    # print('TCP position, ', tcp_pos_workframe)\n",
    "    # print(obj_goal_pos_dist)\n",
    "\n",
    "    # Set obj to goal to smaller than tolerance for testing\n",
    "    # obj_goal_pos_dist[1] = 0.001\n",
    "\n",
    "    # intiailise terminated vector\n",
    "    terminated = torch.zeros((batch_size, 1), dtype=bool).to(device)\n",
    "\n",
    "    # print(\"goal position batch before update \\n\", goal_pos_workframe_batch)\n",
    "    # print(\"goal index batch before update\", targ_traj_list_id_batch)\n",
    "\n",
    "    # Early termination if outside of the tcp limits\n",
    "    if early_termination:\n",
    "        outside_tcp_lims_idx = outside_tcp_lims(cur_obj_pos_workframe, tcp_to_obj_orn, tip_to_obj_pos)\n",
    "        terminated[outside_tcp_lims_idx] = True\n",
    "        rewards[outside_tcp_lims_idx] += env.terminated_early_penalty\n",
    "        # print(\"Outside TPC_lims, \", outside_tcp_lims(tcp_pos_workframe, cur_obj_pos_workframe, tip_to_obj_pos))\n",
    "\n",
    "    # update goals index if subgoal reached\n",
    "    targ_traj_list_id_batch[obj_goal_pos_dist < model_env.termination_pos_dist] += 1\n",
    "\n",
    "    # Terminated is true if last subgoal is reached\n",
    "    terminated[targ_traj_list_id_batch >= model_env.traj_n_points] = True\n",
    "    rewards[targ_traj_list_id_batch >= model_env.traj_n_points] += model_env.reached_goal_reward\n",
    "\n",
    "    # Update goal position batch for none terminated samples\n",
    "    goal_pos_workframe_batch[~terminated[:,0]] = traj_pos_workframe[targ_traj_list_id_batch[~terminated[:,0]]]\n",
    "\n",
    "    # print(\"obj to goal distance\", obj_goal_pos_dist)\n",
    "    # print(\"goal index batch\", targ_traj_list_id_batch)\n",
    "    # print(\"terminated batch\", terminated)\n",
    "    # print(\"goal position index not terminated\", targ_traj_list_id_batch[~terminated[:,0]])\n",
    "    # print(\"The none terminated goals to be updated\", traj_pos_workframe[targ_traj_list_id_batch[~terminated[:,0]]])\n",
    "    # print(\"The updated goals \\n\", goal_pos_workframe_batch)\n",
    "    return terminated\n",
    "\n",
    "def outside_tcp_lims(cur_obj_pos_workframe, tcp_to_obj_orn, tip_to_obj_pos):\n",
    "    # xyz_tcp_dist_to_obj = torch.linalg.norm(tcp_pos_workframe - cur_obj_pos_workframe)\n",
    "    return ((cur_obj_pos_workframe[:, 0] < env.robot.arm.TCP_lims[0,0]) | \n",
    "        (cur_obj_pos_workframe[:, 0] > env.robot.arm.TCP_lims[0,1]) | \n",
    "        (cur_obj_pos_workframe[:, 1] < env.robot.arm.TCP_lims[1,0]) | \n",
    "        (cur_obj_pos_workframe[:, 1] > env.robot.arm.TCP_lims[1,1]) | \n",
    "        (tcp_to_obj_orn > model_env.max_tcp_to_obj_orn) | \n",
    "        (tip_to_obj_pos > model_env.max_tip_to_obj_pos))\n",
    "        # (xyz_tcp_dist_to_obj > env.obj_width / 2))                # TODO: exiting episode when roughly lose contact\n",
    "\n",
    "\n",
    "# Reset environment\n",
    "batch_size = 3\n",
    "env.reset()\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "# Create goal batches (access through model_env)\n",
    "traj_pos_workframe = model_env.traj_pos_workframe.clone()\n",
    "goal_pos_workframe_batch = model_env.goal_pos_workframe_batch.clone()\n",
    "targ_traj_list_id_batch = model_env.targ_traj_list_id_batch\n",
    "# targ_traj_list_id_batch = torch.from_numpy(targ_traj_list_id_batch).long()\n",
    "# targ_traj_list_id_batch[0] = 11\n",
    "\n",
    "tcp_pos = torch.tensor([[0.20, 0.1, 0], [0.30, 0.01, 0], [0.1, 0.01, 0]]).to(device)\n",
    "obj_pos = tcp_pos + torch.tensor([[0.03, 0.0, 0.0], [0.0, 0, 0], [0, 0, 0]]).to(device)\n",
    "tcp_orn = euler_to_quaternion(torch.tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0]])).to(device)\n",
    "obj_orn = euler_to_quaternion(torch.tensor([[0, 0, 10/180*np.pi], [0, 0, 10/180*np.pi], [0, 0, 10/180*np.pi]])).to(device)\n",
    "tcp_to_obj_pos = tcp_pos - obj_pos\n",
    "tcp_to_obj_orn = euler_to_quaternion(torch.tensor([[0, 0, 0/180*np.pi], [0, 0, 10/180*np.pi], [0, 0, 10/180*np.pi]])).to(device)\n",
    "\n",
    "obs = torch.randn(batch_size, obs_shape[0]).to(device)\n",
    "if \"reduced\" in env.observation_mode:\n",
    "    obs[:, :3] =  torch.tensor([[0.2, 0.05, 0.1], [0.2, 0.05, 0.1], [0.2, 0.05, 0.1]]) \n",
    "    obs[:, 13:16] = torch.tensor([[0.2, 0.05, 0.1], [0.2, 0.1, 0.1], [0.2, 0.05, 0.1]])\n",
    "elif env.observation_mode =='goal_aware_tactile_pose_data':\n",
    "    if env.planar_states == True:\n",
    "        # obs[:, 0:2] =  torch.tensor([[0.20, 0.01], [0.3, 0.01], [0.2, 0.01]]).to(device) - goal_pos_workframe_batch[:, 0:2]\n",
    "        obs[:, 2:4] = torch.tensor([[0.4, 0.01], [0.35, 0.1], [0.2, 0.01]]).to(device) - goal_pos_workframe_batch[:, 0:2]\n",
    "    else:\n",
    "        # obs[:, 0:2] =  torch.tensor([[0.20, 0.01], [0.3, 0.01], [0.2, 0.01]]).to(device) - goal_pos_workframe_batch[:, 0:2]\n",
    "        obs[:, 4:6] = torch.tensor([[0.30, 0.01], [0.20, 0.09], [0.2, 0.01]]).to(device) - goal_pos_workframe_batch[:, 0:2]\n",
    "elif env.observation_mode == 'tactile_pose_data': \n",
    "    if env.planar_states == True:\n",
    "        obs[:, 0:2] = tcp_pos[:, 0:2]\n",
    "        obs[:, 4:6] = obj_pos[:, 0:2]\n",
    "        obs[:, 2:4] = tcp_orn[:, 2:4]\n",
    "        obs[:, 6:8] = obj_orn[:, 2:4]\n",
    "    else:\n",
    "        # obs[:, 0:2] =  torch.tensor([[0.2, 0.01], [0.31, 0.01], [0.2, 0.01]]) \n",
    "        obs[:, 4:6] = torch.tensor([[0.31, 0.1], [0.20, 0.01], [0.2, 0.01]])\n",
    "\n",
    "elif env.observation_mode == 'tactile_pose_relative_data': \n",
    "    if env.planar_states == True:\n",
    "        obs[:, 0:2] = tcp_to_obj_pos[:, 0:2]\n",
    "        obs[:, 2:4] = tcp_to_obj_orn[:, 2:4]\n",
    "        obs[:, 4:6] = obj_pos[:, 0:2]\n",
    "        obs[:, 6:8] = obj_orn[:, 2:4]\n",
    "    else:\n",
    "        # obs[:, 0:2] =  torch.tensor([[0.2, 0.01], [0.31, 0.01], [0.2, 0.01]]) \n",
    "        obs[:, 4:6] = torch.tensor([[0.31, 0.1], [0.20, 0.01], [0.2, 0.01]])\n",
    "\n",
    "else:\n",
    "    obs[:, :3] =  torch.tensor([[0.3, 0.1, 0.1], [0.3, 0.1, 0.1], [0.3, 0.1, 0.1]]) \n",
    "    obs[:, 12:15] = torch.tensor([[0.3, 0.1, 0.1], [0.3, 0.1, 0.1], [0.4, 0.1, 0.1]]) \n",
    "\n",
    "act = torch.randn(batch_size, 1).to(device)\n",
    "rewards_test = torch.zeros(batch_size, 1).to(device)\n",
    "rewards_push = torch.zeros(batch_size, 1).to(device)\n",
    "print(termination(act, obs, rewards_test))\n",
    "print(model_env.termination(act, obs, rewards_push))\n",
    "print(rewards_test)\n",
    "print(rewards_push)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True], device='cuda:0')\n",
      "tensor([[False],\n",
      "        [ True]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Test early termination ------------------------\n",
    "early_termination = True\n",
    "\n",
    "tcp_pos_workframe = torch.tensor([[0.01, 0.01, 0], [0.1, 0.01, 0]]).to(device)\n",
    "cur_obj_pos_workframe = tcp_pos_workframe + torch.tensor([[0.0, 0.0, 0.0], [0.0, 0, 0]]).to(device) # The first sample for obj_pos is out of y_lims\n",
    "tcp_orn = euler_to_quaternion(torch.tensor([[0, 0, 10/180*np.pi], [0, 0, 10/180*np.pi]])).to(device)\n",
    "obj_orn = euler_to_quaternion(torch.tensor([[0, 0, 10/180*np.pi], [0, 0, 35/180*np.pi]])).to(device)\n",
    "tcp_to_obj_pos = tcp_pos_workframe - cur_obj_pos_workframe\n",
    "tcp_to_obj_orn = euler_to_quaternion(torch.tensor([[0, 0, 10/180*np.pi], [0, 0, 40/180*np.pi]])).to(device)\n",
    "abs_tip_to_obj_orn = model_env.get_orn_norm(tcp_to_obj_orn)\n",
    "abs_tip_to_obj_pos = torch.linalg.norm(tcp_to_obj_pos,  axis=1)\n",
    "print(outside_tcp_lims(cur_obj_pos_workframe, abs_tip_to_obj_orn, abs_tip_to_obj_pos))\n",
    "\n",
    "batch_size = 2\n",
    "env.reset()\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "# Create goal batches (access through model_env)\n",
    "traj_pos_workframe = model_env.traj_pos_workframe\n",
    "goal_pos_workframe_batch = model_env.goal_pos_workframe_batch\n",
    "targ_traj_list_id_batch = model_env.targ_traj_list_id_batch\n",
    "\n",
    "obs = torch.randn(batch_size, 30).to(device)\n",
    "act = torch.randn(batch_size, 1).to(device)\n",
    "rewards = torch.randn(batch_size).to(device)\n",
    "if \"reduced\" in env.observation_mode:\n",
    "    obs[:, 0:3] = tcp_pos_workframe\n",
    "    obs[:, 13:16] = cur_obj_pos_workframe\n",
    "elif  env.observation_mode == 'goal_aware_tactile_pose_data':\n",
    "    if env.planar_states == True:\n",
    "        # obs[:, 0:2] = tcp_pos_workframe[:, 0:2] - goal_pos_workframe_batch[:, 0:2]\n",
    "        obs[:, 2:4] = cur_obj_pos_workframe[:, 0:2] - goal_pos_workframe_batch[:, 0:2]\n",
    "    else:\n",
    "        # obs[:, 0:3] = tcp_pos_workframe - goal_pos_workframe_batch\n",
    "        obs[:, 4:7] = cur_obj_pos_workframe- goal_pos_workframe_batch  \n",
    "elif env.observation_mode == 'tactile_pose_data':\n",
    "        if env.planar_states == True:\n",
    "            obs[:, 0:2] = tcp_pos_workframe[:, 0:2]\n",
    "            obs[:, 2:4] = tcp_orn[:, 2:4]\n",
    "            obs[:, 4:6] = cur_obj_pos_workframe[:, 0:2]\n",
    "            obs[:, 6:8] = obj_orn[:, 2:4]\n",
    "        else:\n",
    "            # obs[:, 0:3] = tcp_pos_workframe\n",
    "            obs[:, 4:7] = cur_obj_pos_workframe\n",
    "\n",
    "elif env.observation_mode == 'tactile_pose_relative_data': \n",
    "    if env.planar_states == True:\n",
    "        obs[:, 0:2] = tcp_to_obj_pos[:, 0:2]\n",
    "        obs[:, 4:6] = cur_obj_pos_workframe[:, 0:2]\n",
    "        obs[:, 2:4] = tcp_to_obj_orn[:, 2:4]\n",
    "        obs[:, 6:8] = obj_orn[:, 2:4]\n",
    "    else:\n",
    "        # obs[:, 0:2] =  torch.tensor([[0.2, 0.01], [0.31, 0.01], [0.2, 0.01]]) \n",
    "        obs[:, 4:6] = torch.tensor([[0.31, 0.1], [0.20, 0.01], [0.2, 0.01]])\n",
    "else:\n",
    "    obs[:, 0:3] = tcp_pos_workframe\n",
    "    obs[:, 12:15] = cur_obj_pos_workframe\n",
    "print(termination(_, obs, rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.280383]\n",
      "0.28038262921845275\n",
      "[0.272987]\n",
      "0.2729873768426067\n",
      "[0.000007]\n",
      "7.2606433546286254e-06\n"
     ]
    }
   ],
   "source": [
    "# Test rewards\n",
    "# obs = np.expand_dims(env.get_tactile_pose_relative_obs(), 0)\n",
    "# goal = np.expand_dims(env.get_tactile_pose_relative_goal_obs(), 0)\n",
    "obs = np.expand_dims(env.get_observation(), 0)\n",
    "goal = np.expand_dims(env.get_goal_obs(), 0)\n",
    "print(env.get_pos_dist(obs[:, 4:6], goal[:, 4:6]))\n",
    "print(env.xyz_obj_dist_to_goal())\n",
    "print(env.get_orn_dist(obs[:, 6:8], goal[:, 6:8]))\n",
    "print(env.orn_obj_dist_to_goal())\n",
    "print(env.get_orn_dist(obs[:, 2:4], goal[:, 2:4]))\n",
    "print(env.orn_tcp_dist_to_obj())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8901557639099356\n",
      "tensor([[-0.8902],\n",
      "        [-0.8902]], device='cuda:0')\n",
      "tensor([[-0.8902],\n",
      "        [-0.8902]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# --------------- Test reward function  in model env-------------------------------\n",
    "def xyz_obj_dist_to_goal(cur_obj_pos_workframe):\n",
    "\n",
    "    # obj to goal distance\n",
    "    return torch.linalg.norm(cur_obj_pos_workframe - goal_pos_workframe_batch, axis=1)\n",
    "\n",
    "def get_pos_dist(pos_dist_vector):\n",
    "\n",
    "    # obj to goal distance\n",
    "    return torch.linalg.norm(pos_dist_vector, axis=1)\n",
    "\n",
    "def get_pos_diff(pos_1, pos_2):\n",
    "    \"\"\"\n",
    "    Compute the L2 distance\n",
    "    \"\"\"\n",
    "    dist = torch.linalg.norm(pos_1 - pos_2, axis=1)\n",
    "    return dist\n",
    "\n",
    "def orn_obj_dist_to_goal_rpy(cur_obj_rpy_workframe):\n",
    "    cur_obj_orn_workframe = euler_to_quaternion(cur_obj_rpy_workframe)\n",
    "    inner_product = torch.sum(goal_orn_workframe_batch*cur_obj_orn_workframe, 1)\n",
    "    return torch.arccos(torch.clip(2 * (inner_product ** 2) - 1, -1, 1))\n",
    "\n",
    "def orn_obj_dist_to_goal_orn(cur_obj_orn_workframe):\n",
    "    inner_product = torch.sum(goal_orn_workframe_batch*cur_obj_orn_workframe, 1)\n",
    "    return torch.arccos(torch.clip(2 * (inner_product ** 2) - 1, -1, 1))\n",
    "\n",
    "def get_orn_norm(orn_dist_vector):\n",
    "    \"\"\"\n",
    "    Distance between the current obj orientation and goal orientation.\n",
    "    \"\"\"\n",
    "    dist = torch.arccos(torch.clip(\n",
    "        (2 * (orn_dist_vector[:, 3]**2)) - 1, -1, 1))\n",
    "    return dist\n",
    "\n",
    "def get_orn_dist(orn_dist_vector_1, orn_dist_vector_2):\n",
    "    inner_product = torch.sum(orn_dist_vector_1*orn_dist_vector_2, 1)\n",
    "    return torch.arccos(torch.clip(2 * (inner_product ** 2) - 1, -1, 1))\n",
    "\n",
    "def cos_tcp_dist_to_obj(cur_obj_rpy_workframe, tcp_rpy_workframe):\n",
    "    \"\"\"\n",
    "    Cos distance from current orientation of the TCP to the current\n",
    "    orientation of the object\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = cur_obj_rpy_workframe.shape[0]\n",
    "\n",
    "    # tip normal to object normal\n",
    "    cur_obj_orn_workframe = euler_to_quaternion(cur_obj_rpy_workframe)\n",
    "    obj_rot_matrix_workframe = quaternion_rotation_matrix(cur_obj_orn_workframe)\n",
    "    obj_rot_matrix_workframe = torch.reshape(obj_rot_matrix_workframe, (batch_size, 3, 3))\n",
    "    obj_init_vector_workframe = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float32).to(device)\n",
    "    obj_vector_workframe = torch.matmul(obj_rot_matrix_workframe, obj_init_vector_workframe)\n",
    "    # obj_vector_workframe = obj_rot_matrix_workframe[:, :, 0]\n",
    "\n",
    "    tcp_orn_workframe = euler_to_quaternion(tcp_rpy_workframe)\n",
    "    tip_rot_matrix_workframe = quaternion_rotation_matrix(tcp_orn_workframe)\n",
    "    tip_rot_matrix_workframe  = torch.reshape(tip_rot_matrix_workframe, (batch_size, 3, 3))\n",
    "    tip_init_vector_workframe  = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float32).to(device)\n",
    "    tip_vector_workframe  = torch.matmul(tip_rot_matrix_workframe, tip_init_vector_workframe)\n",
    "    # tip_vector_workframe = tip_rot_matrix_workframe[:, :, 0]\n",
    "\n",
    "    obj_tip_dot_product = torch.sum(obj_vector_workframe*tip_vector_workframe, 1)\n",
    "    cos_sim_workfrfame = obj_tip_dot_product / (\n",
    "        torch.linalg.norm(obj_vector_workframe, axis=1) * torch.linalg.norm(tip_vector_workframe, axis=1)\n",
    "    )\n",
    "    cos_dist_workframe = 1 - cos_sim_workfrfame\n",
    "\n",
    "    return cos_dist_workframe\n",
    "\n",
    "def cos_tcp_dist_to_obj_reduced(cur_obj_orn_to_goal_workframe, tcp_orn_to_goal_workframe):\n",
    "    \"\"\"\n",
    "    Cos distance from current orientation of the TCP to the current\n",
    "    orientation of the object\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = cur_obj_orn_to_goal_workframe.shape[0]\n",
    "\n",
    "    # tip normal to object normal\n",
    "    obj_rot_matrix_workframe = quaternion_rotation_matrix(cur_obj_orn_to_goal_workframe)\n",
    "    obj_rot_matrix_workframe = torch.reshape(obj_rot_matrix_workframe, (batch_size, 3, 3))\n",
    "    # obj_init_vector_workframe = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float64)\n",
    "    # obj_vector_workframe = torch.matmul(obj_rot_matrix_workframe, obj_init_vector_workframe)\n",
    "    obj_vector_workframe = obj_rot_matrix_workframe[:, :, 0]\n",
    "\n",
    "    tip_rot_matrix_workframe = quaternion_rotation_matrix(tcp_orn_to_goal_workframe)\n",
    "    tip_rot_matrix_workframe  = torch.reshape(tip_rot_matrix_workframe, (batch_size, 3, 3))\n",
    "    # tip_init_vector_workframe  = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float64)\n",
    "    # tip_vector_workframe  = torch.matmul(tip_rot_matrix_workframe, tip_init_vector_workframe)\n",
    "    tip_vector_workframe = tip_rot_matrix_workframe[:, :, 0]\n",
    "\n",
    "    obj_tip_dot_product = torch.sum(obj_vector_workframe*tip_vector_workframe, 1)\n",
    "    cos_sim_workfrfame = obj_tip_dot_product / (\n",
    "        torch.linalg.norm(obj_vector_workframe, axis=1) * torch.linalg.norm(tip_vector_workframe, axis=1)\n",
    "    )\n",
    "    cos_dist_workframe = 1 - cos_sim_workfrfame \n",
    "\n",
    "    return cos_dist_workframe\n",
    "\n",
    "def cos_tcp_Rz_dist_to_obj(cos_cur_obj_Rz_to_goal_workframe, cos_tcp_Rz_to_goal_workframe):\n",
    "    cos_sim_workframe = torch.cos(\n",
    "        torch.arccos(cos_tcp_Rz_to_goal_workframe) - torch.arccos(cos_cur_obj_Rz_to_goal_workframe)\n",
    "        )\n",
    "    return 1 - cos_sim_workframe\n",
    "\n",
    "def reward(act: torch.Tensor, next_obs: torch.Tensor) -> torch.Tensor:\n",
    "    '''\n",
    "    Caculate the reward given a batch of observations \n",
    "    '''\n",
    "\n",
    "    batch_size = next_obs.shape[0]\n",
    "\n",
    "    if 'reduced' in env.observation_mode: \n",
    "        # tcp_pos_to_goal_workframe = next_obs[:, 0:3]\n",
    "        tcp_orn_to_goal_workframe = next_obs[:, 3:7]\n",
    "        # tcp_lin_vel_workframe = next_obs[:, 7:10]\n",
    "        # tcp_ang_vel_workframe = next_obs[:, 10:13]\n",
    "        cur_obj_pos_to_goal_workframe = next_obs[:, 13:16]\n",
    "        cur_obj_orn_to_goal_workframe = next_obs[:, 16:20]\n",
    "        # cur_obj_lin_vel_workframe = next_obs[:, 20:23]\n",
    "        # cur_obj_ang_vel_workframe = next_obs[:, 23:26]\n",
    "\n",
    "        obj_goal_pos_dist = get_pos_dist(cur_obj_pos_to_goal_workframe)\n",
    "        obj_goal_orn_dist = get_orn_norm(cur_obj_orn_to_goal_workframe)\n",
    "        tip_obj_orn_dist = cos_tcp_dist_to_obj_reduced(cur_obj_orn_to_goal_workframe, tcp_orn_to_goal_workframe)\n",
    "\n",
    "        print(obj_goal_orn_dist)\n",
    "    elif env.observation_mode == 'goal_aware_tactile_pose_data': \n",
    "        if env.planar_states == True: \n",
    "            # tcp_pos_to_goal_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            tcp_orn_to_goal_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "            cur_obj_pos_to_goal_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            cur_obj_orn_to_goal_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "\n",
    "            # tcp_pos_to_goal_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_orn_to_goal_workframe[:, 2:4] = next_obs[:, 0:2]\n",
    "            cur_obj_pos_to_goal_workframe[:, 0:2]= next_obs[:, 2:4]\n",
    "            cur_obj_orn_to_goal_workframe[:, 2:4] = next_obs[:, 4:6]\n",
    "        else:\n",
    "            # tcp_pos_to_goal_workframe = next_obs[:, 0:3]\n",
    "            tcp_orn_to_goal_workframe = next_obs[:, 0:4]\n",
    "            cur_obj_pos_to_goal_workframe = next_obs[:, 4:7]\n",
    "            cur_obj_orn_to_goal_workframe = next_obs[:, 7:11]\n",
    "            \n",
    "        obj_goal_pos_dist = get_pos_dist(cur_obj_pos_to_goal_workframe)\n",
    "        obj_goal_orn_dist = get_orn_norm(cur_obj_orn_to_goal_workframe)\n",
    "        tip_obj_orn_dist = get_orn_dist(cur_obj_orn_to_goal_workframe, tcp_orn_to_goal_workframe)\n",
    "\n",
    "    elif env.observation_mode == 'tactile_pose_data':\n",
    "        if env.planar_states == True:\n",
    "            # tcp_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            tcp_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "            cur_obj_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            cur_obj_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "\n",
    "            # tcp_pos_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_orn_workframe[:, 2:4] = next_obs[:, 2:4]\n",
    "            cur_obj_pos_workframe[:, 0:2]= next_obs[:, 4:6]\n",
    "            cur_obj_orn_workframe[:, 2:4] = next_obs[:, 6:8]\n",
    "        else:   \n",
    "            # tcp_pos_workframe = next_obs[:, 0:3]\n",
    "            tcp_orn_workframe = next_obs[:, 0:4]\n",
    "            cur_obj_pos_workframe = next_obs[:, 4:7]\n",
    "            cur_obj_orn_workframe = next_obs[:, 7:11]\n",
    "\n",
    "        obj_goal_pos_dist = xyz_obj_dist_to_goal(cur_obj_pos_workframe)\n",
    "        obj_goal_orn_dist = orn_obj_dist_to_goal_orn(cur_obj_orn_workframe)\n",
    "        tip_obj_orn_dist = get_orn_dist(cur_obj_orn_workframe, tcp_orn_workframe)\n",
    "        \n",
    "    \n",
    "    elif env.observation_mode == 'tactile_pose_relative_data':\n",
    "\n",
    "        if env.planar_states == True:\n",
    "\n",
    "            tcp_obj_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            tcp_obj_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "            cur_obj_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            cur_obj_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "\n",
    "            tcp_obj_pos_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_obj_orn_workframe[:, 2:4] = next_obs[:, 2:4]\n",
    "            cur_obj_pos_workframe[:, 0:2] = next_obs[:, 4:6]\n",
    "            cur_obj_orn_workframe[:, 2:4] = next_obs[:, 6:8]\n",
    "\n",
    "        else:\n",
    "            NotImplemented\n",
    "\n",
    "        obj_goal_pos_dist = xyz_obj_dist_to_goal(cur_obj_pos_workframe)\n",
    "        obj_goal_orn_dist = orn_obj_dist_to_goal_orn(cur_obj_orn_workframe)\n",
    "        tip_obj_orn_dist = get_orn_norm(tcp_obj_orn_workframe)\n",
    "\n",
    "        # print(obj_goal_pos_dist)\n",
    "        # print(obj_goal_orn_dist)\n",
    "        # print(tip_obj_orn_dist)\n",
    "\n",
    "    else:\n",
    "        # tcp_pos_workframe = next_obs[:, 0:3]\n",
    "        tcp_rpy_workframe = next_obs[:, 3:6]\n",
    "        # tcp_lin_vel_workframe = next_obs[:, 6:9]\n",
    "        # tcp_ang_vel_workframe = next_obs[:, 9:12]\n",
    "        cur_obj_pos_workframe = next_obs[:, 12:15]\n",
    "        cur_obj_rpy_workframe = next_obs[:, 15:18]\n",
    "        # cur_obj_lin_vel_workframe = next_obs[:, 18:21]\n",
    "        # cur_obj_ang_vel_workframe = next_obs[:, 21:24]\n",
    "        # pred_goal_pos_workframe = next_obs[:, 24:27]\n",
    "        # pred_goal_rpy_workframe = next_obs[:, 27:30]\n",
    "\n",
    "        obj_goal_pos_dist = xyz_obj_dist_to_goal(cur_obj_pos_workframe)\n",
    "        obj_goal_orn_dist = orn_obj_dist_to_goal_rpy(cur_obj_rpy_workframe)\n",
    "        tip_obj_orn_dist = cos_tcp_dist_to_obj(cur_obj_rpy_workframe, tcp_rpy_workframe)\n",
    "\n",
    "    reward = -(\n",
    "        (env.W_obj_goal_pos * obj_goal_pos_dist)\n",
    "        + (env.W_obj_goal_orn * obj_goal_orn_dist)\n",
    "        + (env.W_tip_obj_orn * tip_obj_orn_dist)\n",
    "        )\n",
    "    reward = reward[:, None]\n",
    "\n",
    "    return reward\n",
    "\n",
    "# Create observation and goal batch \n",
    "batch_size = 2\n",
    "obs = env.reset()\n",
    "for i in range(100):\n",
    "    obs, _, done, _ = env.step(env.action_space.sample())\n",
    "obs = torch.tensor(obs).to(torch.float32).to(device)\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "obs_batch = torch.tile(obs, (batch_size,) + tuple([1] * obs.ndim))\n",
    "goal_pos_workframe_batch = model_env.goal_pos_workframe_batch\n",
    "goal_orn_workframe_batch = model_env.goal_orn_workframe_batch\n",
    "act = env.action_space.sample()\n",
    "act_batch = torch.tile(torch.tensor(act), (batch_size,) + tuple([1] * obs.ndim)).to(device)\n",
    "\n",
    "print(env.dense_reward(act))\n",
    "print(reward(act_batch, obs_batch))\n",
    "print(model_env.reward(act_batch, obs_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000000 0.000001 0.032107 0.999484]\n",
      "tensor([[0.0000, 0.0000, 0.0321, 0.9995],\n",
      "        [0.0000, 0.0000, 0.0321, 0.9995]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# check update goal function\n",
    "batch_size = 2\n",
    "obs = env.reset()\n",
    "for i in range(100):\n",
    "    obs, _, done, _ = env.step(env.action_space.sample())\n",
    "obs = torch.tensor(obs).to(torch.float32).to(device)\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "obs_batch = torch.tile(obs, (batch_size,) + tuple([1] * obs.ndim))\n",
    "\n",
    "print(env.goal_orn_workframe)\n",
    "model_env.update_goal_orn(obs_batch)\n",
    "print(model_env.goal_orn_workframe_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.8647],\n",
      "        [-3.2853],\n",
      "        [-0.9562],\n",
      "        ...,\n",
      "        [-1.1884],\n",
      "        [-5.3406],\n",
      "        [-0.0000]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[-4.8647],\n",
      "        [-3.2853],\n",
      "        [-0.9562],\n",
      "        ...,\n",
      "        [-1.1884],\n",
      "        [-5.3406],\n",
      "        [-0.0000]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Test reward and terminal function using next_observ from model.sample()\n",
    "planning_horizon = agent.optimizer.horizon\n",
    "# initialise action sequence\n",
    "action_lb = env.action_space.low.tolist()\n",
    "action_ub = env.action_space.high.tolist()\n",
    "initial_solution = (((torch.tensor(action_lb) + torch.tensor(action_ub)) / 2)\n",
    "            .float().to(device)\n",
    "        )\n",
    "initial_solution = initial_solution.repeat((planning_horizon, 1))\n",
    "mu, dispersion = agent.optimizer.optimizer._init_population_params(initial_solution)\n",
    "action_sequences = torch.zeros((500,) + initial_solution.shape).to(device)\n",
    "action_sequences = agent.optimizer.optimizer._sample_population(mu, dispersion, action_sequences)\n",
    "\n",
    "# Intialise state and create model state for model input\n",
    "env.reset()\n",
    "for i in range(100):\n",
    "    obs, _, done, _ = env.step(env.action_space.sample())\n",
    "initial_state = obs\n",
    "tiling_shape = (20 * 500,) + tuple(\n",
    "    [1] * initial_state.ndim\n",
    ")\n",
    "initial_obs_batch = np.tile(initial_state, tiling_shape).astype(np.float32)\n",
    "model_state = model_env.reset(initial_obs_batch, return_as_np=False)\n",
    "\n",
    "# get action for time step\n",
    "action_for_step = action_sequences[:, 0, :]\n",
    "action_batch = torch.repeat_interleave(\n",
    "                    action_for_step, 20, dim=0\n",
    "                )\n",
    "\n",
    "# Get next observation from model\n",
    "(\n",
    "    next_observs,\n",
    "    pred_rewards,\n",
    "    pred_terminals,\n",
    "    next_model_state,\n",
    ") = model_env.dynamics_model.sample(\n",
    "    action_batch,\n",
    "    model_state,\n",
    "    deterministic=False,\n",
    "    rng=model_env._rng,\n",
    ")\n",
    "\n",
    "# Next obervation types\n",
    "# print(next_observs.type())\n",
    "# print(next_observs.dtype)\n",
    "# print(next_observs.shape)\n",
    "\n",
    "# Create observation and goal batch \n",
    "batch_size = next_observs.shape[0]\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "# Get global variables needed for reward function\n",
    "goal_pos_workframe_batch = model_env.goal_pos_workframe_batch\n",
    "goal_orn_workframe_batch = model_env.goal_orn_workframe_batch\n",
    "act = env.action_space.sample()\n",
    "act_batch = torch.tile(torch.tensor(act), (batch_size,) + tuple([1] * obs.ndim)).to(device)\n",
    "\n",
    "print(reward(act_batch, next_observs))\n",
    "print(model_env.reward(act_batch, next_observs))\n",
    "print(any((reward(act_batch, next_observs) == model_env.reward(act_batch, next_observs))))\n",
    "\n",
    "# Get the global variables needed for termination function\n",
    "traj_pos_workframe = model_env.traj_pos_workframe\n",
    "targ_traj_list_id_batch = model_env.targ_traj_list_id_batch\n",
    "random_reward = reward(act_batch, next_observs)\n",
    "\n",
    "# print(termination(_, next_observs))\n",
    "# print(model_env.termination(_, next_observs))\n",
    "# print(model_env.termination_fn(act, next_observs))\n",
    "print(all((termination(_, next_observs, random_reward) == model_env.termination(_, next_observs, random_reward))))\n",
    "# print(random_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Test evaluation_action_sequences\n",
    "planning_horizon = agent.optimizer.horizon\n",
    "# initialise action sequence\n",
    "# action_lb = env.action_space.low.tolist()\n",
    "# action_ub = env.action_space.high.tolist()\n",
    "# initial_solution = (((torch.tensor(action_lb) + torch.tensor(action_ub)) / 2)\n",
    "#             .float()\n",
    "#         )\n",
    "# initial_solution = initial_solution.repeat((15, 1))\n",
    "# mu, dispersion = agent.optimizer.optimizer._init_population_params(initial_solution)\n",
    "# action_sequences = torch.zeros((500,) + initial_solution.shape)\n",
    "# action_sequences = agent.optimizer.optimizer._sample_population(mu, dispersion, action_sequences)\n",
    "# # print(initial_solution.shape)\n",
    "\n",
    "# create random action sequences\n",
    "initial_solution = torch.from_numpy(np.array([env.action_space.sample() for _ in range(planning_horizon)])).float().to(device)\n",
    "# print(initial_solution.shape)\n",
    "mu, dispersion = agent.optimizer.optimizer._init_population_params(initial_solution)\n",
    "action_sequences = torch.zeros((500,) + initial_solution.shape).to(device)\n",
    "action_sequences = agent.optimizer.optimizer._sample_population(mu, dispersion, action_sequences)\n",
    "\n",
    "# Initialise environment\n",
    "initial_state = env.reset()\n",
    "\n",
    "# evaluate sequences\n",
    "print(model_env.evaluate_action_sequences(action_sequences, initial_state, 20).shape)\n",
    "print(any(model_env.targ_traj_list_id_batch!=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states_from_obs(obs):\n",
    "    if \"goal_excluded\" in env.observation_mode:\n",
    "        if env.planar_states == True:\n",
    "            tcp_pos_workframe = np.zeros(3)\n",
    "            tcp_orn_workframe = np.zeros(4)\n",
    "            cur_obj_pos_workframe = np.zeros(3)\n",
    "            cur_obj_orn_workframe = np.zeros(4)\n",
    "\n",
    "            tcp_pos_workframe[0:2] = obs[0:2]\n",
    "            tcp_orn_workframe[2:4] = obs[2:4]\n",
    "            cur_obj_pos_workframe[0:2]= obs[4:6]\n",
    "            cur_obj_orn_workframe[2:4] = obs[6:8]\n",
    "        else:   \n",
    "            # tcp_pos_workframe = obs[0:3]\n",
    "            # tcp_orn_workframe = obs[0:4]\n",
    "            cur_obj_pos_workframe = obs[4:7]\n",
    "            # cur_obj_orn_workframe = obs[7:11]\n",
    "\n",
    "    else:\n",
    "        if env.planar_states == True: \n",
    "            # tcp_pos_to_goal_workframe = np.zeros(3)\n",
    "            # tcp_orn_to_goal_workframe = np.zeros(4)\n",
    "            cur_obj_pos_to_goal_workframe = np.zeros(3)\n",
    "            # cur_obj_orn_to_goal_workframe = np.zeros(4)\n",
    "\n",
    "            # tcp_pos_to_goal_workframe[0:2] = obs[0:2]\n",
    "            # tcp_orn_to_goal_workframe[2:4] = obs[0:2]\n",
    "            cur_obj_pos_to_goal_workframe[0:2]= obs[2:4]\n",
    "            # cur_obj_orn_to_goal_workframe[2:4] = obs[4:6]\n",
    "        else:\n",
    "            # tcp_pos_to_goal_workframe = obs[0:3]\n",
    "            # tcp_orn_to_goal_workframe = obs[0:4]\n",
    "            cur_obj_pos_to_goal_workframe = obs[4:7]\n",
    "            # cur_obj_orn_to_goal_workframe = obs[7:11]\n",
    "\n",
    "        # tcp_pos_workframe = obs[0:3] + env.goal_pos_workframe\n",
    "        cur_obj_pos_workframe = cur_obj_pos_to_goal_workframe + env.goal_pos_workframe\n",
    "\n",
    "    return tcp_pos_workframe, tcp_orn_workframe, cur_obj_pos_workframe, cur_obj_orn_workframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples stored 2000\n"
     ]
    }
   ],
   "source": [
    "# # make directory for saving data\n",
    "# data_columns = ['trial','trial_steps', 'time_steps', 'tcp_x','tcp_y','tcp_z','contact_x', 'contact_y', 'contact_z', 'tcp_Rz', 'contact_Rz', 'goal_x', 'goal_y', 'goal_z', 'rewards', 'contact', 'dones']\n",
    "# training_result_directory = os.path.join(work_dir, \"training_result\")\n",
    "# os.makedirs(training_result_directory, exist_ok=True)\n",
    "\n",
    "# def save_data(arg):\n",
    "#     initial_buffer = []\n",
    "#     (env, obs, action, next_obs, reward, done, info) = arg\n",
    "#     (tcp_pos_workframe, \n",
    "#     tcp_orn_workframe,\n",
    "#     cur_obj_pos_workframe, \n",
    "#     cur_obj_orn_workframe) = get_states_from_obs(env, obs)\n",
    "#     cur_obj_rpy_workframe = env._pb.getEulerFromQuaternion(cur_obj_orn_workframe)\n",
    "#     tcp_rpy_workframe = env._pb.getEulerFromQuaternion(cur_obj_orn_workframe)\n",
    "#     initial_buffer.append(np.hstack([0, \n",
    "#                                     0, \n",
    "#                                     0,\n",
    "#                                     tcp_pos_workframe, \n",
    "#                                     cur_obj_pos_workframe,\n",
    "#                                     tcp_rpy_workframe[2],\n",
    "#                                     cur_obj_rpy_workframe[2],\n",
    "#                                     env.goal_pos_workframe, \n",
    "#                                     reward, \n",
    "#                                     info[\"tip_in_contact\"],\n",
    "#                                     done]))\n",
    "#     pd.DataFrame(initial_buffer).to_csv(os.path.join(training_result_directory, \"{}_result.csv\".format(\"initial_buffer\")), mode='a', header=False)\n",
    "\n",
    "\n",
    "replay_buffer = common_util.create_replay_buffer(cfg, obs_shape, act_shape, rng=rng)\n",
    "common_util.rollout_agent_trajectories(\n",
    "    env,\n",
    "    initial_buffer_size, # initial exploration steps\n",
    "    planning.RandomAgent(env),\n",
    "    {}, # keyword arguments to pass to agent.act()\n",
    "    replay_buffer=replay_buffer,\n",
    "    trial_length=trial_length,\n",
    "    # callback=save_data,\n",
    ")\n",
    "\n",
    "print(\"# samples stored\", replay_buffer.num_stored)\n",
    "\n",
    "# df = pd.read_csv(os.path.join(training_result_directory, 'initial_buffer_result.csv'), names = data_columns)\n",
    "# loss_contact = False\n",
    "# print(len(df.query(\"contact==@loss_contact\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [0.0]\n",
    "val_scores = [0.0]\n",
    "\n",
    "def train_callback(_model, _total_calls, _epoch, tr_loss, val_score, _best_val):\n",
    "    train_losses.append(tr_loss)\n",
    "    val_scores.append(val_score.mean().item())   # this returns val score per ensemble model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x270 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_axes(_axs, _frame, _text, _trial, _steps_trial, _plan_time, _train_time, _all_rewards, _goal_reached, _train_loss, _val_loss, force_update=False):\n",
    "    if not force_update and (_steps_trial % 10 != 0):\n",
    "        return\n",
    "    _axs[0].imshow(_frame)\n",
    "    _axs[0].set_xticks([])\n",
    "    _axs[0].set_yticks([])\n",
    "    _axs[0].tick_params(axis='x', colors='white')\n",
    "    _axs[0].tick_params(axis='y', colors='white')\n",
    "    _axs[1].clear()\n",
    "    _axs[1].set_xlim([0, num_trials + .1])\n",
    "    _axs[1].set_ylim([min(_all_rewards), 0])\n",
    "    _axs[1].set_xlabel(\"Trial\")\n",
    "    _axs[1].set_ylabel(\"Trial reward\")\n",
    "    _axs[1].xaxis.label.set_color('white')\n",
    "    _axs[1].yaxis.label.set_color('white')\n",
    "    _axs[1].tick_params(axis='x', colors='white')\n",
    "    _axs[1].tick_params(axis='y', colors='white')\n",
    "    _axs[1].plot(_all_rewards, 'bs-', _goal_reached, 'rs')\n",
    "    _text.set_text(\"Trial {}: {} steps\\nTrain Loss: {:.2f}\\nVal Loss: {:.3g}\\nPlan time: {:.2f} s/step\\nTrain time: {:.2f} s\".format(_trial + 1, _steps_trial, _train_loss, _val_loss, _plan_time, _train_time))\n",
    "    display.display(plt.gcf())  \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "text_kwargs = dict(ha='center', va='center', fontsize=28, color='C1')\n",
    "def update_axes_text(_axs, _trial, _steps_trial, _plan_time, _train_time, _all_rewards, _goal_reached, _train_loss, _val_loss, force_update=False):\n",
    "    if not force_update and (_steps_trial % 10 != 0):\n",
    "        return\n",
    "    _axs[0].clear()\n",
    "    _axs[0].text(0.5, 0.5, \n",
    "    \"Trial {}: {} steps\\nTrain Loss: {:.2f}\\nVal Loss: {:.3g}\\nPlan time: {:.2f} s/step\\nTrain time: {:.2f} s\".format(_trial + 1, _steps_trial, _train_loss, _val_loss, _plan_time, _train_time), **text_kwargs)\n",
    "    _axs[1].clear()\n",
    "    _axs[1].set_xlim([0, num_trials + .1])\n",
    "    _axs[1].set_ylim([min(_all_rewards), 0])\n",
    "    _axs[1].set_xlabel(\"Trial\")\n",
    "    _axs[1].set_ylabel(\"Trial reward\")\n",
    "    _axs[1].xaxis.label.set_color('white')\n",
    "    _axs[1].yaxis.label.set_color('white')\n",
    "    _axs[1].tick_params(axis='x', colors='white')\n",
    "    _axs[1].tick_params(axis='y', colors='white')\n",
    "    _axs[1].plot(_all_rewards, 'bs-', _goal_reached, 'rs')\n",
    "    display.display(plt.gcf())  \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "# Test plot function\n",
    "env.reset()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 3.75), gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "ax_text = axs[0].text(130, 80, \"\")\n",
    "ax_text.set_color('white')\n",
    "all_rewards = np.random.randint(-500, 0, num_trials + 1)\n",
    "goal_reached = np.random.randint(-500, 0, num_trials + 1)\n",
    "steps = np.sort(np.random.randint(0,10000, len(all_rewards)))\n",
    "plan_time = np.random.rand()\n",
    "train_time = np.random.rand()\n",
    "# update_axes(axs,env.render(mode=\"rgb_array\"),  ax_text, 0, 0, plan_time, train_time, all_rewards, goal_reached, train_losses[-1], val_scores[-1], force_update=True)\n",
    "update_axes_text(axs, 0, 0, plan_time, train_time, all_rewards, goal_reached, train_losses[-1], val_scores[-1], force_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# --- Doing env step using the agent and adding to model dataset ---\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m start_plan_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m next_obs, reward, done, info \u001b[39m=\u001b[39m common_util\u001b[39m.\u001b[39;49mstep_env_and_add_to_buffer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m     env, obs, agent, {}, replay_buffer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m plan_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_plan_time\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m update_axes_text(axs, trial, steps_trial, plan_time, train_time,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m     all_rewards, goal_reached, train_losses[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], val_scores[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/util/common.py:603\u001b[0m, in \u001b[0;36mstep_env_and_add_to_buffer\u001b[0;34m(env, obs, agent, agent_kwargs, replay_buffer, callback, agent_uses_low_dim_obs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     agent_obs \u001b[39m=\u001b[39m obs\n\u001b[0;32m--> 603\u001b[0m action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mact(agent_obs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49magent_kwargs)\n\u001b[1;32m    604\u001b[0m next_obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m    605\u001b[0m replay_buffer\u001b[39m.\u001b[39madd(obs, action, next_obs, reward, done)\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:684\u001b[0m, in \u001b[0;36mTrajectoryOptimizerAgent.act\u001b[0;34m(self, obs, optimizer_callback, **_kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory_eval_fn(obs, action_sequences)\n\u001b[1;32m    683\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 684\u001b[0m plan \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m    685\u001b[0m     trajectory_eval_fn, callback\u001b[39m=\u001b[39;49moptimizer_callback\n\u001b[1;32m    686\u001b[0m )\n\u001b[1;32m    687\u001b[0m plan_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactions_to_use\u001b[39m.\u001b[39mextend([a \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m plan[: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplan_freq]])\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:558\u001b[0m, in \u001b[0;36mTrajectoryOptimizer.optimize\u001b[0;34m(self, trajectory_eval_fn, callback)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    540\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    541\u001b[0m     trajectory_eval_fn: Callable[[torch\u001b[39m.\u001b[39mTensor], torch\u001b[39m.\u001b[39mTensor],\n\u001b[1;32m    542\u001b[0m     callback: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    543\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    544\u001b[0m     \u001b[39m\"\"\"Runs the trajectory optimization.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \n\u001b[1;32m    546\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39m        (tuple of np.ndarray and float): the best action sequence.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m     best_solution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m    559\u001b[0m         trajectory_eval_fn,\n\u001b[1;32m    560\u001b[0m         x0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprevious_solution,\n\u001b[1;32m    561\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    562\u001b[0m     )\n\u001b[1;32m    563\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_last_solution:\n\u001b[1;32m    564\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprevious_solution \u001b[39m=\u001b[39m best_solution\u001b[39m.\u001b[39mroll(\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplan_freq, dims\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:296\u001b[0m, in \u001b[0;36mMPPIOptimizer.optimize\u001b[0;34m(self, obj_fun, x0, callback, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m population \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(\n\u001b[1;32m    291\u001b[0m     population \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupper_bound, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupper_bound, population\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    293\u001b[0m population \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(\n\u001b[1;32m    294\u001b[0m     population \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlower_bound, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlower_bound, population\n\u001b[1;32m    295\u001b[0m )\n\u001b[0;32m--> 296\u001b[0m values \u001b[39m=\u001b[39m obj_fun(population)\n\u001b[1;32m    297\u001b[0m values[values\u001b[39m.\u001b[39misnan()] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1e-10\u001b[39m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:681\u001b[0m, in \u001b[0;36mTrajectoryOptimizerAgent.act.<locals>.trajectory_eval_fn\u001b[0;34m(action_sequences)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrajectory_eval_fn\u001b[39m(action_sequences):\n\u001b[0;32m--> 681\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrajectory_eval_fn(obs, action_sequences)\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:744\u001b[0m, in \u001b[0;36mcreate_trajectory_optim_agent_for_model.<locals>.trajectory_eval_fn\u001b[0;34m(initial_state, action_sequences)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrajectory_eval_fn\u001b[39m(initial_state, action_sequences):\n\u001b[0;32m--> 744\u001b[0m     \u001b[39mreturn\u001b[39;00m model_env\u001b[39m.\u001b[39;49mevaluate_action_sequences(\n\u001b[1;32m    745\u001b[0m         action_sequences, initial_state\u001b[39m=\u001b[39;49minitial_state, num_particles\u001b[39m=\u001b[39;49mnum_particles\n\u001b[1;32m    746\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/models/model_env_pushing.py:697\u001b[0m, in \u001b[0;36mModelEnvPushing.evaluate_action_sequences\u001b[0;34m(self, action_sequences, initial_state, num_particles)\u001b[0m\n\u001b[1;32m    693\u001b[0m action_for_step \u001b[39m=\u001b[39m action_sequences[:, time_step, :]\n\u001b[1;32m    694\u001b[0m action_batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrepeat_interleave(\n\u001b[1;32m    695\u001b[0m     action_for_step, num_particles, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    696\u001b[0m )\n\u001b[0;32m--> 697\u001b[0m _, rewards, dones, model_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m    698\u001b[0m     action_batch, model_state, sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    699\u001b[0m )\n\u001b[1;32m    700\u001b[0m rewards[terminated] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    701\u001b[0m terminated \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m dones\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/models/model_env_pushing.py:150\u001b[0m, in \u001b[0;36mModelEnvPushing.step\u001b[0;34m(self, actions, model_state, sample)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_goal_orn(next_observs)\n\u001b[1;32m    145\u001b[0m rewards \u001b[39m=\u001b[39m (\n\u001b[1;32m    146\u001b[0m     pred_rewards\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_fn(actions, next_observs)\n\u001b[1;32m    149\u001b[0m )\n\u001b[0;32m--> 150\u001b[0m dones \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtermination_fn(actions, next_observs, rewards)\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m pred_terminals \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModelEnv doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yet support simulating terminal indicators.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/models/model_env_pushing.py:387\u001b[0m, in \u001b[0;36mModelEnvPushing.termination\u001b[0;34m(self, act, next_obs, rewards)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39m# Create terminated vector, terminated is true if last subgoal is reached\u001b[39;00m\n\u001b[1;32m    386\u001b[0m terminated \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((batch_size, \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 387\u001b[0m terminated[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarg_traj_list_id_batch \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraj_n_points] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    388\u001b[0m rewards[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarg_traj_list_id_batch \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraj_n_points] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreached_goal_reward\n\u001b[1;32m    390\u001b[0m \u001b[39m# Early termination if outside of the tcp limits\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x270 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create logging folder\n",
    "print(f\"Results will be saved at {work_dir}.\")\n",
    "\n",
    "# Create a trainer for the model\n",
    "model_trainer = models.ModelTrainer(dynamics_model, optim_lr=1e-3, weight_decay=5e-5)\n",
    "\n",
    "# Create visualization objects\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 3.75), gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "ax_text = axs[0].text(130, 80, \"\")\n",
    "ax_text.set_color('white')\n",
    "\n",
    "# Main PETS loop\n",
    "all_rewards = [0]\n",
    "total_steps = [0]\n",
    "goal_reached = [0]\n",
    "training_result = []\n",
    "plan_time = 0.0\n",
    "train_time = 0.0\n",
    "\n",
    "record_video = True\n",
    "record_video_frequency = 5\n",
    "\n",
    "for trial in range(num_trials):\n",
    "\n",
    "    # Reset \n",
    "    obs = env.reset()    \n",
    "    agent.reset()\n",
    "    done = False\n",
    "    trial_reward = 0.0\n",
    "    trial_pb_steps = 0.0\n",
    "    steps_trial = 0\n",
    "\n",
    "    # Record video\n",
    "    if record_video and (trial+1) % record_video_frequency == 0:\n",
    "        record_every_n_frames = 3\n",
    "        render_img = env.render(mode=\"rgb_array\")\n",
    "        render_img_size = (render_img.shape[1], render_img.shape[0])\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(\n",
    "            os.path.join(work_dir, \"training_policy_trial_{}.mp4\".format((trial+1))),\n",
    "            fourcc,\n",
    "            24.0,\n",
    "            render_img_size,\n",
    "        )\n",
    "        \n",
    "    update_axes_text(axs, trial, steps_trial, plan_time, train_time,\n",
    "        all_rewards, goal_reached, train_losses[-1], val_scores[-1])\n",
    "    # update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, plan_time, train_time,\n",
    "    #     all_rewards, goal_reached, train_losses[-1], val_scores[-1])\n",
    "    \n",
    "    (tcp_pos_workframe, \n",
    "    tcp_rpy_workframe,\n",
    "    cur_obj_pos_workframe, \n",
    "    cur_obj_rpy_workframe) = env.get_obs_workframe()\n",
    "    training_result.append(np.hstack([trial, \n",
    "                                    steps_trial, \n",
    "                                    trial_pb_steps,\n",
    "                                    tcp_pos_workframe, \n",
    "                                    cur_obj_pos_workframe,\n",
    "                                    tcp_rpy_workframe[2],\n",
    "                                    cur_obj_rpy_workframe[2],\n",
    "                                    env.goal_pos_workframe, \n",
    "                                    trial_reward, \n",
    "                                    False,\n",
    "                                    done]))\n",
    "    while not done:\n",
    "\n",
    "        if steps_trial == 0:\n",
    "            # --------------- Model Training -----------------\n",
    "            dynamics_model.update_normalizer(replay_buffer.get_all())  # update normalizer stats            \n",
    "            dataset_train, dataset_val = common_util.get_basic_buffer_iterators(\n",
    "                replay_buffer,\n",
    "                batch_size=cfg.overrides.model_batch_size,\n",
    "                val_ratio=cfg.overrides.validation_ratio,\n",
    "                ensemble_size=ensemble_size,\n",
    "                shuffle_each_epoch=True,\n",
    "                bootstrap_permutes=False,  # build bootstrap dataset using sampling with replacement\n",
    "            )\n",
    "            \n",
    "            start_train_time = time.time()\n",
    "            model_trainer.train(\n",
    "                dataset_train, \n",
    "                dataset_val=dataset_val, \n",
    "                num_epochs=50, \n",
    "                patience=50, \n",
    "                callback=train_callback,\n",
    "                silent=True)\n",
    "            train_time = time.time() - start_train_time\n",
    "\n",
    "            if work_dir is not None:\n",
    "                dynamics_model.save(str(work_dir))\n",
    "                replay_buffer.save(work_dir)\n",
    "\n",
    "        # --- Doing env step using the agent and adding to model dataset ---\n",
    "        start_plan_time = time.time()\n",
    "        next_obs, reward, done, info = common_util.step_env_and_add_to_buffer(\n",
    "            env, obs, agent, {}, replay_buffer)\n",
    "        plan_time = time.time() - start_plan_time\n",
    "\n",
    "        update_axes_text(axs, trial, steps_trial, plan_time, train_time,\n",
    "            all_rewards, goal_reached, train_losses[-1], val_scores[-1])\n",
    "        # update_axes(\n",
    "        #     axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, plan_time, train_time, \n",
    "        #     all_rewards, goal_reached,  train_losses[-1], val_scores[-1])\n",
    "\n",
    "        obs = next_obs\n",
    "        trial_reward += reward\n",
    "        trial_pb_steps += info[\"num_of_pb_steps\"]\n",
    "        steps_trial += 1\n",
    "\n",
    "        # Save data for plotting training performance\n",
    "  \n",
    "        (tcp_pos_workframe, \n",
    "        tcp_rpy_workframe,\n",
    "        cur_obj_pos_workframe, \n",
    "        cur_obj_rpy_workframe) = env.get_obs_workframe()\n",
    "        training_result.append(np.hstack([trial,\n",
    "                                        steps_trial,\n",
    "                                        trial_pb_steps * env._sim_time_step,\n",
    "                                        tcp_pos_workframe, \n",
    "                                        cur_obj_pos_workframe, \n",
    "                                        tcp_rpy_workframe[2],\n",
    "                                        cur_obj_rpy_workframe[2],\n",
    "                                        env.goal_pos_workframe, \n",
    "                                        trial_reward, \n",
    "                                        info[\"tip_in_contact\"],\n",
    "                                        done]))\n",
    "        \n",
    "        # Record video at every n trials\n",
    "        if record_video and (trial+1) % record_video_frequency == 0 and steps_trial % record_every_n_frames == 0:\n",
    "            render_img = env.render(mode=\"rgb_array\")\n",
    "            render_img = cv2.cvtColor(render_img, cv2.COLOR_BGR2RGB)\n",
    "            out.write(render_img)\n",
    "\n",
    "        if steps_trial == trial_length:\n",
    "            break\n",
    "\n",
    "    all_rewards.append(trial_reward)\n",
    "    total_steps.append(steps_trial + total_steps[-1])\n",
    "\n",
    "    # save goal reached data during training\n",
    "    if env.single_goal_reached:\n",
    "        goal_reached.append(trial_reward)\n",
    "    else:\n",
    "        goal_reached.append(0)\n",
    "\n",
    "    # release video at every n trials\n",
    "    if record_video and (trial+1) % record_video_frequency == 0:\n",
    "        out.release()\n",
    "\n",
    "update_axes_text(axs, trial, steps_trial, plan_time, train_time,\n",
    "    all_rewards, goal_reached, train_losses[-1], val_scores[-1], force_update=True)\n",
    "# update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, plan_time, train_time, \n",
    "#     all_rewards, goal_reached, train_losses[-1], val_scores[-1], force_update=True)\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(total_steps[1:], all_rewards[1:], 'bs-', total_steps[1:], goal_reached[1:], 'rs')\n",
    "ax.set_xlabel(\"Samples\")\n",
    "ax.set_ylabel(\"Trial reward\")\n",
    "fig.savefig(os.path.join(work_dir, \"output.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_push_plots(df, trials, directory):\n",
    "    loss_contact = False\n",
    "    for trial in range(trials):\n",
    "        fig_xy, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.plot(df.query(\"trial==@trial\")[\"tcp_x\"], df.query(\"trial==@trial\")[\"tcp_y\"], \"b-\", label='tcp psosition')\n",
    "        ax.plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"tcp_x\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"tcp_y\"], \"g+\", markersize=20)\n",
    "        ax.plot(df.query(\"trial==@trial\")[\"contact_x\"], df.query(\"trial==@trial\")[\"contact_y\"], \"r-\", label='contact psosition')\n",
    "        ax.plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"contact_x\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"contact_y\"], \"gx\", markersize=20)\n",
    "        ax.plot(df.query(\"trial==@trial\")[\"goal_x\"].iloc[0], df.query(\"trial==@trial\")[\"goal_y\"].iloc[0], \"x\", markersize=20, markeredgecolor=\"black\", label=\"goal position\")\n",
    "        \n",
    "        for i, rows in df.query(\"trial==@trial\").iterrows():\n",
    "            if i % 10 == 0:\n",
    "                tcp_x, tcp_y, tcp_Rz= rows[\"tcp_x\"], rows[\"tcp_y\"], rows[\"tcp_Rz\"]\n",
    "                tcp_dx, tcp_dy = 0.05 * np.cos(tcp_Rz), 0.05 * np.sin(tcp_Rz)\n",
    "                plt.arrow(tcp_x, tcp_y, tcp_dx, tcp_dy, color='b')\n",
    "                obj_x, obj_y, obj_Rz= rows[\"contact_x\"], rows[\"contact_y\"], rows[\"contact_Rz\"]\n",
    "                obj_dx, obj_dy = 0.05 * np.cos(obj_Rz), 0.05 * np.sin(obj_Rz)\n",
    "                plt.arrow(obj_x, obj_y, obj_dx, obj_dy, color='r')\n",
    "        \n",
    "        ax.set_xlabel(\"x workframe\")\n",
    "        ax.set_ylabel(\"y workframe\")\n",
    "        ax.set_xlim([env.robot.arm.TCP_lims[0, 0], env.robot.arm.TCP_lims[0, 1]])\n",
    "        ax.set_ylim([env.robot.arm.TCP_lims[1, 0], env.robot.arm.TCP_lims[1, 1]])\n",
    "        ax.legend()\n",
    "        fig_xy.savefig(os.path.join(directory, \"workframe_plot_trial_{}.png\".format(trial)))\n",
    "        plt.close(fig_xy)\n",
    "\n",
    "        fig_time_xy, axs = plt.subplots(1, 2, figsize=(14, 3.75), gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "        axs[0].plot(df.query(\"trial==@trial\")[\"time_steps\"], df.query(\"trial==@trial\")[\"tcp_x\"], \"bs\", label='tcp ')\n",
    "        axs[0].plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"time_steps\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"tcp_x\"], \"g+\", markersize=20)\n",
    "        axs[0].plot(df.query(\"trial==@trial\")[\"time_steps\"], df.query(\"trial==@trial\")[\"contact_x\"], \"rs\", label='contact')\n",
    "        axs[0].plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"time_steps\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"contact_x\"], \"gx\", markersize=20)\n",
    "        axs[0].set_xlabel(\"Time steps (s)\")\n",
    "        axs[0].set_ylabel(\"x axis workframe\")\n",
    "        axs[0].set_ylim([env.robot.arm.TCP_lims[0, 0], env.robot.arm.TCP_lims[0, 1]])\n",
    "        axs[0].legend()\n",
    "        axs[1].plot(df.query(\"trial==@trial\")[\"time_steps\"], df.query(\"trial==@trial\")[\"tcp_y\"], \"bs\", label='tcp')\n",
    "        axs[1].plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"time_steps\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"tcp_y\"], \"g+\", markersize=20)\n",
    "        axs[1].plot(df.query(\"trial==@trial\")[\"time_steps\"], df.query(\"trial==@trial\")[\"contact_y\"], \"rs\", label='contact')\n",
    "        axs[1].plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"time_steps\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"contact_y\"], \"gx\", markersize=20)\n",
    "        axs[1].set_xlabel(\"Time steps (s)\")\n",
    "        axs[1].set_ylabel(\"y axis workframe\")\n",
    "        axs[1].set_ylim([env.robot.arm.TCP_lims[1, 0], env.robot.arm.TCP_lims[1, 1]])\n",
    "        axs[1].legend()\n",
    "        fig_time_xy.savefig(os.path.join(directory, \"time_plot_trial_{}.png\".format(trial)))\n",
    "        plt.close(fig_time_xy)\n",
    "\n",
    "# Save data \n",
    "training_result = np.array(training_result)\n",
    "data_columns = ['trial','trial_steps', 'time_steps', 'tcp_x','tcp_y','tcp_z','contact_x', 'contact_y', 'contact_z', 'tcp_Rz', 'contact_Rz', 'goal_x', 'goal_y', 'goal_z', 'rewards', 'contact', 'dones']\n",
    "df_training = pd.DataFrame(training_result, columns = data_columns)\n",
    "pd.DataFrame(training_result).to_csv(os.path.join(work_dir, \"training_results.csv\"))\n",
    "\n",
    "# Plot the training results\n",
    "training_result_directory = os.path.join(work_dir, \"training_result\")\n",
    "if not os.path.exists(training_result_directory):\n",
    "    os.mkdir(training_result_directory)\n",
    "else:\n",
    "    for filename in os.listdir(training_result_directory):\n",
    "        file_path = os.path.join(training_result_directory, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "plot_and_save_push_plots(df_training, num_trials, training_result_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main PETS loop\n",
    "num_test_trials = 10\n",
    "all_rewards = []\n",
    "evaluation_result = []\n",
    "goal_reached = []\n",
    "plan_time = 0.0\n",
    "train_time = 0.0\n",
    "save_vid = True\n",
    "render = True\n",
    "\n",
    "if save_vid:\n",
    "    record_every_n_frames = 1\n",
    "    render_img = env.render(mode=\"rgb_array\")\n",
    "    render_img_size = (render_img.shape[1], render_img.shape[0])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(\n",
    "        os.path.join(work_dir, \"evaluated_policy.mp4\"),\n",
    "        fourcc,\n",
    "        24.0,\n",
    "        render_img_size,\n",
    "    )\n",
    "\n",
    "for trial in range(num_test_trials):\n",
    "    obs = env.reset()    \n",
    "    agent.reset()\n",
    "    \n",
    "    done = False\n",
    "    trial_reward = 0.0\n",
    "    trial_pb_steps = 0.0\n",
    "    steps_trial = 0\n",
    "\n",
    "    tcp_pos_workframe, _, _, _, _ = env.robot.arm.get_current_TCP_pos_vel_workframe()\n",
    "    cur_obj_pos_workframe = get_states_from_obs(obs)\n",
    "    evaluation_result.append(np.hstack([trial, \n",
    "                                        steps_trial, \n",
    "                                        trial_pb_steps,\n",
    "                                        tcp_pos_workframe, \n",
    "                                        cur_obj_pos_workframe, \n",
    "                                        env.goal_pos_workframe, \n",
    "                                        trial_reward, \n",
    "                                        False,\n",
    "                                        done]))\n",
    "    while not done:\n",
    "\n",
    "        # --- Doing env step using the agent and adding to model dataset ---\n",
    "        start_plan_time = time.time()\n",
    "        action = agent.act(obs, **{})\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        plan_time = time.time() - start_plan_time\n",
    "\n",
    "        if render:\n",
    "            render_img = env.render(mode=\"rgb_array\")\n",
    "        else:\n",
    "            render_img = None\n",
    "        \n",
    "        obs = next_obs\n",
    "        trial_reward += reward\n",
    "        trial_pb_steps += info[\"num_of_pb_steps\"]\n",
    "        steps_trial += 1\n",
    "\n",
    "        tcp_pos_workframe, _, _, _, _ = env.robot.arm.get_current_TCP_pos_vel_workframe()\n",
    "        cur_obj_pos_workframe = get_states_from_obs(obs)\n",
    "        evaluation_result.append(np.hstack([trial, \n",
    "                                            steps_trial, \n",
    "                                            trial_pb_steps * env._sim_time_step,\n",
    "                                            tcp_pos_workframe, \n",
    "                                            cur_obj_pos_workframe, \n",
    "                                            env.goal_pos_workframe, \n",
    "                                            trial_reward, \n",
    "                                            info[\"tip_in_contact\"],\n",
    "                                            done]))\n",
    "            \n",
    "         # use record_every_n_frames to reduce size sometimes\n",
    "        if save_vid and steps_trial % record_every_n_frames == 0:\n",
    "\n",
    "            # warning to enable rendering\n",
    "            if render_img is None:\n",
    "                sys.exit('Must be rendering to save video')\n",
    "\n",
    "            render_img = cv2.cvtColor(render_img, cv2.COLOR_BGR2RGB)\n",
    "            out.write(render_img)\n",
    "\n",
    "        if steps_trial == trial_length:\n",
    "            break\n",
    "    \n",
    "    print(\"Terminated at step {} with reward {}, goal reached: {}\".format(steps_trial, trial_reward, env.single_goal_reached))\n",
    "    all_rewards.append(trial_reward)\n",
    "\n",
    "    # save goal reached data during training\n",
    "    if env.single_goal_reached:\n",
    "        goal_reached.append(trial_reward)\n",
    "    else:\n",
    "        goal_reached.append(0)\n",
    "\n",
    "if save_vid:\n",
    "    out.release()\n",
    "\n",
    "print(\"The average reward over {} episodes is {}\".format(num_test_trials, np.mean(all_rewards)))\n",
    "\n",
    "# Save data \n",
    "evaluation_result = np.array(evaluation_result)\n",
    "df_evaluation = pd.DataFrame(evaluation_result, columns = data_columns)\n",
    "pd.DataFrame(evaluation_result).to_csv(os.path.join(work_dir, \"evaluation_results.csv\"))\n",
    "\n",
    "# plot evaluation results\n",
    "evaluation_result_directory = os.path.join(work_dir, \"evaluation_result\")\n",
    "if not os.path.exists(evaluation_result_directory):\n",
    "    os.mkdir(evaluation_result_directory)\n",
    "else:\n",
    "    for filename in os.listdir(evaluation_result_directory):\n",
    "        file_path = os.path.join(evaluation_result_directory, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "plot_and_save_push_plots(df_evaluation, num_test_trials, evaluation_result_directory)\n",
    "\n",
    "# Plot evaluation results\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(all_rewards, 'bs-', goal_reached, 'rs')\n",
    "ax.set_xlabel(\"Trial\")\n",
    "ax.set_ylabel(\"Trial reward\")\n",
    "fig.savefig(os.path.join(work_dir, \"evaluation_output.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check model learning and rollout predictions to see if code is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test optimisation iterations for CEM\n",
    "train_losses = []\n",
    "val_scores = []\n",
    "\n",
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "\n",
    "# Create a gym-like environment to encapsulate the model\n",
    "model_env = models.ModelEnvPushing(env, dynamics_model, termination_fn=None, reward_fn=None, generator=generator)\n",
    "\n",
    "replay_buffer = common_util.create_replay_buffer(cfg, obs_shape, act_shape, rng=rng)\n",
    "common_util.rollout_agent_trajectories(\n",
    "    env,\n",
    "    buffer_size, # initial exploration steps\n",
    "    planning.RandomAgent(env),\n",
    "    {}, # keyword arguments to pass to agent.act()\n",
    "    replay_buffer=replay_buffer,\n",
    "    trial_length=trial_length\n",
    ")\n",
    "\n",
    "print(\"# samples stored\", replay_buffer.num_stored)\n",
    "\n",
    "# Train model first\n",
    "model_trainer = models.ModelTrainer(dynamics_model, optim_lr= 1e-3, weight_decay=5e-5)\n",
    "dynamics_model.update_normalizer(replay_buffer.get_all())\n",
    "dataset_train, dataset_val = common_util.get_basic_buffer_iterators(\n",
    "    replay_buffer,\n",
    "    batch_size=cfg.overrides.model_batch_size,\n",
    "    val_ratio=cfg.overrides.validation_ratio,\n",
    "    ensemble_size=ensemble_size,\n",
    "    shuffle_each_epoch=True,\n",
    "    bootstrap_permutes=False,  # build bootstrap dataset using sampling with replacement\n",
    ")\n",
    "\n",
    "start_train_time = time.time()\n",
    "model_trainer.train(\n",
    "    dataset_train, \n",
    "    dataset_val=dataset_val, \n",
    "    num_epochs=100, \n",
    "    patience=50, \n",
    "    callback=train_callback,\n",
    "    silent=True)\n",
    "train_time = time.time() - start_train_time\n",
    "\n",
    "print(\"Training time: \", train_time)\n",
    "print(\"Train Loss: {}, Val Loss: {}\".format(train_losses[-1], val_scores[-1]))\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
    "ax[0].plot(train_losses)\n",
    "ax[0].set_xlabel(\"Total training epochs\")\n",
    "ax[0].set_ylabel(\"Training loss (avg. NLL)\")\n",
    "ax[0].xaxis.label.set_color('white')\n",
    "ax[0].yaxis.label.set_color('white')\n",
    "ax[0].tick_params(axis='x', colors='white')\n",
    "ax[0].tick_params(axis='y', colors='white')\n",
    "ax[1].plot(val_scores)\n",
    "ax[1].set_xlabel(\"Total training epochs\")\n",
    "ax[1].set_ylabel(\"Validation score (avg. MSE)\")\n",
    "ax[1].xaxis.label.set_color('white')\n",
    "ax[1].yaxis.label.set_color('white')\n",
    "ax[1].tick_params(axis='x', colors='white')\n",
    "ax[1].tick_params(axis='y', colors='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Test model one set of action sequences from buffer to see exploding -------\n",
    "# states still occur\n",
    "\n",
    "planning_horizon = 10\n",
    "\n",
    "# Get action sequence from buffer\n",
    "data = replay_buffer.get_all()\n",
    "action_sequences = data.act[0:planning_horizon,:]\n",
    "action_sequences = np.tile(action_sequences, (5,1,1)).astype(np.float32)\n",
    "action_sequences = torch.from_numpy(action_sequences)\n",
    "# print(action_sequences.shape)\n",
    "\n",
    "# Initialise state and create model input\n",
    "initial_state = data.obs[0]\n",
    "# print(initial_state.shape)\n",
    "initial_obs_batch = np.tile(initial_state, (5,1)).astype(np.float32)\n",
    "# print(initial_obs_batch.shape)\n",
    "model_state = model_env.reset(initial_obs_batch, return_as_np=False)\n",
    "# print(model_state['propagation_indices'])\n",
    "\n",
    "batch_size = initial_obs_batch.shape[0]\n",
    "total_rewards = torch.zeros(batch_size, 1)\n",
    "terminated = torch.zeros(batch_size, 1, dtype=bool)\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "print(data.obs[1][0:3])\n",
    "print(data.next_obs[1][0:3])\n",
    "print(data.act[1])\n",
    "\n",
    "for time_step in range(planning_horizon):\n",
    "    print(torch.mean(model_state[\"obs\"], 0)[0:3])\n",
    "    # print(model_state[\"obs\"].shape)\n",
    "    # print(torch.mean(model_state[\"obs\"]))\n",
    "    action_for_step = action_sequences[:, time_step, :]\n",
    "    # print(action_for_step[0])\n",
    "\n",
    "    # Re-initialise model state from data buffer with every time step (1 step rollouts)\n",
    "    # Comment out to do planning_horizon step rollouts\n",
    "    # initial_state = data.obs[time_step]\n",
    "    # initial_obs_batch = np.tile(initial_state, (5,1)).astype(np.float32)\n",
    "    # initial_obs_batch = torch.from_numpy(initial_obs_batch)\n",
    "    # model_state.update({'obs': initial_obs_batch})\n",
    "    # action_batch = torch.repeat_interleave(\n",
    "    #     action_for_step, 20, dim=0\n",
    "    # )\n",
    "\n",
    "    action_batch = action_for_step\n",
    "    # ---------------- Use model_env.step -----------------\n",
    "    # _, rewards, dones, model_state = model_env.step(\n",
    "    #     action_batch, model_state, sample=True\n",
    "    # )\n",
    "    # rewards[terminated] = 0\n",
    "    # terminated |= dones\n",
    "    # total_rewards += rewards\n",
    "\n",
    "    # -------------- Use one_dim_tr_model sample -------------\n",
    "    # with torch.no_grad():\n",
    "    #     next_observs, _, _, next_model_state, = model_env.dynamics_model.sample(\n",
    "    #         action_batch, model_state, deterministic=False, rng=model_env._rng,\n",
    "    #     )\n",
    "\n",
    "    # -------------- Use model.sample_1d() --------------------\n",
    "    # with torch.no_grad():\n",
    "    #     obs = model_state[\"obs\"]\n",
    "    #     model_in = model_env.dynamics_model._get_model_input(model_state[\"obs\"], action_batch)\n",
    "    #     next_observs, _ = model_env.dynamics_model.model.sample_1d(\n",
    "    #         model_in, model_state, rng=model_env._rng, deterministic=False\n",
    "    #     )\n",
    "    #     next_observs += obs\n",
    "    #     model_state[\"obs\"] = next_observs\n",
    "\n",
    "    # -------------- Use model.forward()-------------------------\n",
    "    with torch.no_grad():\n",
    "        obs = model_state[\"obs\"]\n",
    "        model_in = model_env.dynamics_model._get_model_input(model_state[\"obs\"], action_batch)\n",
    "        means, logvars = model_env.dynamics_model.model.forward(\n",
    "            model_in, rng=model_env._rng, propagation_indices=model_state[\"propagation_indices\"]\n",
    "        )\n",
    "        variances = logvars.exp()\n",
    "        stds = torch.sqrt(variances)\n",
    "        # stds = torch.ones((5,30))\n",
    "        next_observs = torch.normal(means, stds, generator=model_env._rng)\n",
    "        # next_observs = means\n",
    "        # print(torch.mean(means))\n",
    "        # print(torch.mean(logvars))\n",
    "        # print(torch.mean(stds))\n",
    "        if dynamics_model.target_normalizer:\n",
    "            next_observs = dynamics_model.target_normalizer.denormalize(next_observs)\n",
    "\n",
    "        if dynamics_model.target_is_delta:\n",
    "            next_observs += obs\n",
    "        model_state[\"obs\"] = next_observs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation  function\n",
    "def evaluate(env, agent, training_trial_num, work_dir):\n",
    "    \n",
    "    all_rewards = []\n",
    "    evaluation_result = []\n",
    "    goal_reached = []\n",
    "    plan_time = 0.0\n",
    "    train_time = 0.0\n",
    "    save_vid = True\n",
    "    render = True\n",
    "\n",
    "    if save_vid:\n",
    "        record_every_n_frames = 1\n",
    "        render_img = env.render(mode=\"rgb_array\")\n",
    "        render_img_size = (render_img.shape[1], render_img.shape[0])\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(\n",
    "            os.path.join(work_dir, \"evaluated_policy_training_trial_{}.mp4\".format(training_trial_num)),\n",
    "            fourcc,\n",
    "            24.0,\n",
    "            render_img_size,\n",
    "        )\n",
    "\n",
    "    for trial in range(1):\n",
    "        obs = env.reset()    \n",
    "        agent.reset()\n",
    "        \n",
    "        done = False\n",
    "        trial_reward = 0.0\n",
    "        trial_pb_steps = 0.0\n",
    "        steps_trial = 0\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # --- Doing env step using the agent and adding to model dataset ---\n",
    "            start_plan_time = time.time()\n",
    "            action = agent.act(obs, **{})\n",
    "            next_obs, reward, done, info = env.step(action)\n",
    "            plan_time = time.time() - start_plan_time\n",
    "\n",
    "            if render:\n",
    "                render_img = env.render(mode=\"rgb_array\")\n",
    "            else:\n",
    "                render_img = None\n",
    "            \n",
    "            obs = next_obs\n",
    "            trial_reward += reward\n",
    "            trial_pb_steps += info[\"num_of_pb_steps\"]\n",
    "            steps_trial += 1\n",
    "\n",
    "                \n",
    "            # use record_every_n_frames to reduce size sometimes\n",
    "            if save_vid and steps_trial % record_every_n_frames == 0:\n",
    "\n",
    "                # warning to enable rendering\n",
    "                if render_img is None:\n",
    "                    sys.exit('Must be rendering to save video')\n",
    "\n",
    "                render_img = cv2.cvtColor(render_img, cv2.COLOR_BGR2RGB)\n",
    "                out.write(render_img)\n",
    "\n",
    "            if steps_trial == trial_length:\n",
    "                break\n",
    "        \n",
    "        all_rewards.append(trial_reward)\n",
    "\n",
    "        # save goal reached data during training\n",
    "        if env.single_goal_reached:\n",
    "            goal_reached.append(trial_reward)\n",
    "        else:\n",
    "            goal_reached.append(0)\n",
    "\n",
    "    if save_vid:\n",
    "        out.release()\n",
    "\n",
    "# create a evaluation environment\n",
    "eval_env = gym.make(env_name, **env_kwargs)\n",
    "eval_env.seed(seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tactile_gym_mbrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "288c20f4f30562b85a793c8b692fd9c626a3a2ddfa32fea47b77030b2eed9a18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
